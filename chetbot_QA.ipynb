{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gossiping-QA-Dataset : https://www.kaggle.com/zake7749/pttgossipingcorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Gossiping-QA-Dataset-2_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>為什麼 聖結石 會被酸而 這群人 不會？</td>\n",
       "      <td>質感 劇本 成員 都差很多好嗎 不要拿腎結石來污辱這群人</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>為什麼慶祝228會被罵可是慶端午不會？</td>\n",
       "      <td>因為屈原不是台灣人，是楚國人。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>有沒有戰神阿瑞斯的八卦?</td>\n",
       "      <td>爵士就是阿瑞斯 男主角最後死了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>理論與實務最脫節的系</td>\n",
       "      <td>哪個系不脫節...你問最不脫節的簡單多了...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>為什麼PTT這麼多人看棒球</td>\n",
       "      <td>肥宅才看棒球　系壘一堆胖子</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               question                        answer\n",
       "0  為什麼 聖結石 會被酸而 這群人 不會？  質感 劇本 成員 都差很多好嗎 不要拿腎結石來污辱這群人\n",
       "1   為什麼慶祝228會被罵可是慶端午不會？               因為屈原不是台灣人，是楚國人。\n",
       "2          有沒有戰神阿瑞斯的八卦?               爵士就是阿瑞斯 男主角最後死了\n",
       "3            理論與實務最脫節的系       哪個系不脫節...你問最不脫節的簡單多了...\n",
       "4         為什麼PTT這麼多人看棒球                 肥宅才看棒球　系壘一堆胖子"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'為什麼 聖結石 會被酸而 這群人 不會？'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['question'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'質感 劇本 成員 都差很多好嗎 不要拿腎結石來污辱這群人'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['answer'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\") #'bert-base-uncased'\n",
    "g_vocab_size = g_tokenizer.vocab_size\n",
    "g_max_input_length = g_tokenizer.max_model_input_sizes['bert-base-chinese']  # 512\n",
    "g_bert = BertModel.from_pretrained('bert-base-chinese')\n",
    "g_bert_emb_dim = g_bert.config.to_dict()['hidden_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_cut(sentence):\n",
    "    tokens = g_tokenizer.tokenize(sentence)\n",
    "    tokens = tokens[:g_max_input_length-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21128"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self, train_Q, train_A):\n",
    "        \n",
    "        self.train_Q = train_Q\n",
    "        self.train_A = train_A\n",
    "        self.length = len(train_Q)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "           \n",
    "        Q_token = tokenize_and_cut(self.train_Q[index])\n",
    "        A_token = tokenize_and_cut(self.train_A[index])\n",
    "        \n",
    "        Q_index = g_tokenizer.convert_tokens_to_ids(Q_token)\n",
    "        A_index = g_tokenizer.convert_tokens_to_ids(A_token)\n",
    "        \n",
    "        Q_tensor = torch.tensor([Q_index]).transpose(0, 1).to(g_device)\n",
    "        A_tensor = torch.tensor([A_index]).transpose(0, 1).to(g_device)\n",
    "        \n",
    "        return Q_tensor, A_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = QADataset(df['question'], df['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4158],\n",
       "         [ 784],\n",
       "         [7938],\n",
       "         [5469],\n",
       "         [5178],\n",
       "         [4767],\n",
       "         [3298],\n",
       "         [6158],\n",
       "         [7000],\n",
       "         [5445],\n",
       "         [6857],\n",
       "         [5408],\n",
       "         [ 782],\n",
       "         [ 679],\n",
       "         [3298],\n",
       "         [8043]], device='cuda:0'),\n",
       " tensor([[6549],\n",
       "         [2697],\n",
       "         [1206],\n",
       "         [3315],\n",
       "         [2768],\n",
       "         [1519],\n",
       "         [6963],\n",
       "         [2345],\n",
       "         [2523],\n",
       "         [1914],\n",
       "         [1962],\n",
       "         [1621],\n",
       "         [ 679],\n",
       "         [6206],\n",
       "         [2897],\n",
       "         [5575],\n",
       "         [5178],\n",
       "         [4767],\n",
       "         [ 889],\n",
       "         [3738],\n",
       "         [6802],\n",
       "         [6857],\n",
       "         [5408],\n",
       "         [ 782]], device='cuda:0'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "\n",
    "    Q_tensor = [s[0] for s in samples]\n",
    "    A_tensor = [s[1] for s in samples]\n",
    "    \n",
    "    Q_tensor = pad_sequence(Q_tensor)\n",
    "    A_tensor = pad_sequence(A_tensor)\n",
    "    \n",
    "    masks_Q_tensors = torch.zeros(Q_tensor.size(), dtype=torch.long).to(g_device)\n",
    "    masks_Q_tensors = masks_Q_tensors.masked_fill(Q_tensor != 0, 1)\n",
    "    \n",
    "    masks_A_tensors = torch.zeros(A_tensor.size(), dtype=torch.long).to(g_device)\n",
    "    masks_A_tensors = masks_A_tensors.masked_fill(A_tensor != 0, 1)\n",
    "    \n",
    "    return Q_tensor, A_tensor, masks_Q_tensors, masks_A_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774114"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 5000\n",
    "t_set, v_set = torch.utils.data.random_split(train_set, [temp, len(df)-temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(t_set, shuffle=True, batch_size=10, collate_fn=create_mini_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model: https://github.com/demi6od/ChatBot/blob/master/image/ChatBotBertTransformer.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransBertEncoder(nn.Module):\n",
    "    def __init__(self, nhead=8, nlayers=6, dropout=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        # bert encoder\n",
    "        self.bert = g_bert\n",
    "\n",
    "        # transformer encoder, as bert last layer fine-tune\n",
    "        self.pos_encoder = PositionalEncoding(g_bert_emb_dim, dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=g_bert_emb_dim, nhead=nhead)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers)\n",
    "\n",
    "    def forward(self, src, mask):\n",
    "        # src = [src len, batch size]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # embedded = [src len, batch size, emb dim]\n",
    "            embedded = self.bert(src.transpose(0, 1), attention_mask=mask.transpose(0, 1))[0].transpose(0, 1)\n",
    "\n",
    "        # embedded = self.pos_encoder(embedded)\n",
    "\n",
    "        # src_mask = nn.Transformer().generate_square_subsequent_mask(len(embedded)).to(g_device)\n",
    "\n",
    "        # outputs = [src len, batch size, hid dim * n directions]\n",
    "        outputs = self.transformer_encoder(embedded)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransBertDecoder(nn.Module):\n",
    "    def __init__(self, nhead=8, nlayers=6, dropout=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        # bert encoder\n",
    "        self.bert = g_bert\n",
    "\n",
    "        self.pos_decoder = PositionalEncoding(g_bert_emb_dim, dropout)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=g_bert_emb_dim, nhead=nhead)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=nlayers)\n",
    "\n",
    "        self.fc_out = nn.Linear(g_bert_emb_dim, g_vocab_size)\n",
    "\n",
    "    def forward(self, tgt, mask, meaning, teacher_forcing_ratio = 0.01):\n",
    "        # tgt = [output_len, batch size]\n",
    "\n",
    "        output_len = tgt.size(0)\n",
    "        batch_size = tgt.size(1)\n",
    "        # decide if we are going to use teacher forcing or not\n",
    "        teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "        if teacher_force and self.training:\n",
    "            tgt_emb_total = torch.zeros(output_len, batch_size, g_bert_emb_dim).to(g_device)\n",
    "\n",
    "            for t in range(0, output_len):\n",
    "                with torch.no_grad():\n",
    "                    tgt_emb = self.bert(tgt[:t+1].transpose(0, 1), attention_mask=mask.transpose(0, 1))[0].transpose(0, 1)\n",
    "                tgt_emb_total[t] = tgt_emb[-1]\n",
    "\n",
    "            tgt_mask = nn.Transformer().generate_square_subsequent_mask(len(tgt_emb_total)).to(g_device)\n",
    "            decoder_output = self.transformer_decoder(tgt=tgt_emb_total,\n",
    "                                                      memory=meaning,\n",
    "                                                      tgt_mask=tgt_mask)\n",
    "            predictions = self.fc_out(decoder_output)\n",
    "        else:\n",
    "            # initialized the input of the decoder with sos_idx (start of sentence token idx)\n",
    "            output = torch.full((output_len+1, batch_size), g_tokenizer.cls_token_id, dtype=torch.long, device=g_device)\n",
    "            predictions = torch.zeros(output_len, batch_size, g_vocab_size).to(g_device)\n",
    "\n",
    "            for t in range(0, output_len):\n",
    "                with torch.no_grad():\n",
    "                    tgt_emb = self.bert(output[:t+1].transpose(0, 1), attention_mask=mask[:t+1].transpose(0, 1))[0].transpose(0, 1)\n",
    "\n",
    "                # tgt_emb = [t, batch size, emb dim]\n",
    "                # tgt_emb = self.pos_encoder(tgt_emb)\n",
    "\n",
    "                tgt_mask = nn.Transformer().generate_square_subsequent_mask(len(tgt_emb)).to(g_device)\n",
    "\n",
    "                # decoder_output = [t, batch size, emb dim]\n",
    "                decoder_output = self.transformer_decoder(tgt=tgt_emb,\n",
    "                                                          memory=meaning,\n",
    "                                                          tgt_mask=tgt_mask)\n",
    "\n",
    "                # prediction = [batch size, vocab size]\n",
    "                prediction = self.fc_out(decoder_output[-1])\n",
    "\n",
    "                # predictions = [output_len, batch size, vocab size]\n",
    "                predictions[t] = prediction\n",
    "\n",
    "                one_hot_idx = prediction.argmax(1)\n",
    "\n",
    "                # output  = [output len, batch size]\n",
    "                output[t+1] = one_hot_idx\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GruEncoder(nn.Module):\n",
    "    \"\"\"compress the request embeddings to meaning\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, input_size):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output, hidden = self.gru(input)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GruDecoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(output_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, src, tgt, hidden):\n",
    "        # first input to the decoder is the <CLS> tokens\n",
    "        fc_output = src[0].unsqueeze(0)\n",
    "        tgt_len = tgt.size(0)\n",
    "        batch_size = tgt.size(1)\n",
    "\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(tgt_len, batch_size, g_bert_emb_dim).to(g_device)\n",
    "\n",
    "        for t in range(0, tgt_len):\n",
    "            # insert input token embedding, previous hidden state and the context state\n",
    "            # receive output tensor (predictions) and new hidden state\n",
    "            gru_output, hidden = self.gru(fc_output, hidden)\n",
    "\n",
    "            fc_output = self.fc(gru_output)\n",
    "\n",
    "            # place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = fc_output\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogDNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # ResNet, dropout on first 3 layers\n",
    "        input = self.dropout(input)\n",
    "\n",
    "        output = input + F.relu(self.fc1(input))\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        output = output + F.relu(self.fc2(output))\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        output = output + self.fc3(output)  # no relu to keep negative values\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, transbert_encoder, transbert_decoder, gru_encoder, gru_decoder, dialog_dnn):\n",
    "        super().__init__()\n",
    "\n",
    "        self.transbert_encoder = transbert_encoder\n",
    "        self.transbert_decoder = transbert_decoder\n",
    "\n",
    "        self.gru_encoder = gru_encoder\n",
    "        self.gru_decoder = gru_decoder\n",
    "\n",
    "        self.dialog_dnn = dialog_dnn\n",
    "\n",
    "    def forward(self, src, tgt, mask_src, mask_tgt, teacher_forcing_ratio):\n",
    "        request_embeddings = self.transbert_encoder(src,mask_src)\n",
    "        request_meaning = self.gru_encoder(request_embeddings)\n",
    "\n",
    "        if TRAIN_DIALOG:\n",
    "            response_meaning = self.dialog_dnn(request_meaning)\n",
    "        else:\n",
    "            response_meaning = request_meaning   \n",
    "\n",
    "        response_embeddings = self.gru_decoder(request_embeddings, tgt, response_meaning)\n",
    "        response = self.transbert_decoder(tgt, mask_tgt, response_embeddings, teacher_forcing_ratio)\n",
    "\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_chat(sentences):\n",
    "    print(\"chatbot: \", end=\"\")\n",
    "    for word_embeds in sentences:\n",
    "        word_embed = word_embeds[0]\n",
    "        # find one shot index from word embedding\n",
    "        max_idx_t = word_embed.argmax()\n",
    "        max_idx = max_idx_t.item()\n",
    "        word = g_tokenizer.convert_ids_to_tokens(max_idx)\n",
    "        print(word, end=\" \")\n",
    "    print(\"\")  # new line at the end of sentence\n",
    "\n",
    "\n",
    "def print_index_tensor(sentences):\n",
    "    print(\"target: \", end=\"\")\n",
    "    for word_embeds in sentences:\n",
    "        word_embed = word_embeds[0]\n",
    "        max_idx = word_embed.item()\n",
    "        word = g_tokenizer.convert_ids_to_tokens(max_idx)\n",
    "        print(word, end=\" \")\n",
    "    print(\"\")  # new line at the end of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = g_vocab_size\n",
    "OUTPUT_DIM = g_vocab_size\n",
    "ENC_EMB_DIM = g_bert_emb_dim\n",
    "DEC_EMB_DIM = g_bert_emb_dim\n",
    "HID_DIM = 2048  # 5 * 200\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "TRANSFORMER_ENCODER_LAYER = 1  # bert fine-tune\n",
    "TRANSFORMER_DECODER_LAYER = 3  # semantics -> morphology -> syntax\n",
    "TRANSFORMER_HEAD = 8\n",
    "\n",
    "transbert_encoder = TransBertEncoder(TRANSFORMER_HEAD, TRANSFORMER_ENCODER_LAYER, ENC_DROPOUT)\n",
    "transbert_decoder = TransBertDecoder(TRANSFORMER_HEAD, TRANSFORMER_DECODER_LAYER, DEC_DROPOUT)\n",
    "gru_encoder = GruEncoder(HID_DIM, ENC_EMB_DIM)\n",
    "gru_decoder = GruDecoder(HID_DIM, DEC_EMB_DIM)\n",
    "dialog_dnn = DialogDNN(HID_DIM, HID_DIM, HID_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_model = Seq2Seq(transbert_encoder, transbert_decoder, gru_encoder, gru_decoder, dialog_dnn).to(g_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (transbert_encoder): TransBertEncoder(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (pos_encoder): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (transformer_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transbert_decoder): TransBertDecoder(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (pos_decoder): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (transformer_decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_out): Linear(in_features=768, out_features=21128, bias=True)\n",
       "  )\n",
       "  (gru_encoder): GruEncoder(\n",
       "    (gru): GRU(768, 2048)\n",
       "  )\n",
       "  (gru_decoder): GruDecoder(\n",
       "    (gru): GRU(768, 2048)\n",
       "    (fc): Linear(in_features=2048, out_features=768, bias=True)\n",
       "  )\n",
       "  (dialog_dnn): DialogDNN(\n",
       "    (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (fc3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(g_model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=g_tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # src = [src len, batch size]\n",
    "# # tgt = [output_len, batch size]\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     x,y = train_set.__getitem__(1)\n",
    "#     print(x.size(), y.size())\n",
    "\n",
    "#     optimizer.zero_grad()\n",
    "#     output =  g_model(x,y, 0.01)\n",
    "#     print(output.size())\n",
    "#     print(\"--------------\")\n",
    "#     output_dim = output.shape[-1]\n",
    "#     print(output[:-1].view(-1, output_dim).size(),y[:-1].view(-1).size())\n",
    "#     loss = loss_fn(output[:-1].view(-1, output_dim), y[:-1].view(-1))\n",
    "#     print(loss)\n",
    "#     print(\"--------------\")\n",
    "#     print_index_tensor(x)\n",
    "#     print_chat(output)\n",
    "#     print_index_tensor(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774114"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_model = torch.load('./model_test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 0 1/625 loss : tensor(7.3564, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 2/625 loss : tensor(7.0149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 3/625 loss : tensor(7.0279, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 4/625 loss : tensor(6.9637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 西 門 町 有 啥 可 以 吸 引 韓 國 人 的 [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "target: 別 的 不 說 挺 那 種 舔 中 的 台 商 幹 嘛 ? 被 韓 國 幹 翻 剛 好 啦 \n",
      "e : 0 5/625 loss : tensor(6.5678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 6/625 loss : tensor(6.8087, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 7/625 loss : tensor(6.8763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 8/625 loss : tensor(6.7949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 9/625 loss : tensor(6.8268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 10/625 loss : tensor(6.7032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 11/625 loss : tensor(7.2274, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 12/625 loss : tensor(6.6406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 13/625 loss : tensor(7.4334, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 14/625 loss : tensor(6.9580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 15/625 loss : tensor(6.7318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 16/625 loss : tensor(6.9298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 17/625 loss : tensor(6.8875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 18/625 loss : tensor(6.5416, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 19/625 loss : tensor(7.1046, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 20/625 loss : tensor(6.9348, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 21/625 loss : tensor(6.9329, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 22/625 loss : tensor(6.8732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 23/625 loss : tensor(7.5537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 24/625 loss : tensor(7.0548, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 25/625 loss : tensor(6.8902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 26/625 loss : tensor(6.8952, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 27/625 loss : tensor(6.5369, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 28/625 loss : tensor(6.7456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 29/625 loss : tensor(6.8184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 30/625 loss : tensor(6.7921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 31/625 loss : tensor(7.2904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 32/625 loss : tensor(7.2899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 33/625 loss : tensor(7.1645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 34/625 loss : tensor(6.9459, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 蘇 花 [UNK] , 花 蓮 回 新 竹 的 方 案 八 卦 [PAD] [PAD] [PAD] \n",
      "target: 車 和 人 上 船 或 請 一 天 假 明 天 中 橫 合 歡 山 埔 里 新 竹 [PAD] [PAD] [PAD] \n",
      "e : 0 35/625 loss : tensor(6.8223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 36/625 loss : tensor(6.6232, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 37/625 loss : tensor(6.5742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 38/625 loss : tensor(6.6203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 39/625 loss : tensor(7.6623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 40/625 loss : tensor(6.7415, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 41/625 loss : tensor(7.4088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 42/625 loss : tensor(6.9202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 43/625 loss : tensor(7.0242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 44/625 loss : tensor(6.6538, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 45/625 loss : tensor(6.7499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 46/625 loss : tensor(6.6640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 47/625 loss : tensor(6.9320, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 48/625 loss : tensor(6.9903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 49/625 loss : tensor(7.1038, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 50/625 loss : tensor(6.8953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 51/625 loss : tensor(7.1262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 52/625 loss : tensor(6.8282, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 53/625 loss : tensor(6.6626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 54/625 loss : tensor(6.8705, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 55/625 loss : tensor(6.8381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 56/625 loss : tensor(6.5408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 57/625 loss : tensor(6.3747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 58/625 loss : tensor(6.8623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 59/625 loss : tensor(6.7258, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 60/625 loss : tensor(6.9802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 61/625 loss : tensor(6.5994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 62/625 loss : tensor(6.8137, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 63/625 loss : tensor(6.6353, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 64/625 loss : tensor(7.0323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 65/625 loss : tensor(6.6191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 66/625 loss : tensor(6.7226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 67/625 loss : tensor(6.5071, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 68/625 loss : tensor(6.9117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 69/625 loss : tensor(6.8535, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 70/625 loss : tensor(6.9012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 71/625 loss : tensor(6.6684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 72/625 loss : tensor(7.0200, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 73/625 loss : tensor(7.0887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 74/625 loss : tensor(6.4985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 75/625 loss : tensor(6.5884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 76/625 loss : tensor(6.9783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 77/625 loss : tensor(6.6283, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 78/625 loss : tensor(7.6799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 79/625 loss : tensor(7.0475, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 80/625 loss : tensor(6.7359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 81/625 loss : tensor(6.8437, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 82/625 loss : tensor(7.1635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 83/625 loss : tensor(6.8660, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 84/625 loss : tensor(7.2511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 85/625 loss : tensor(6.8824, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 86/625 loss : tensor(6.8297, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 87/625 loss : tensor(6.8053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 88/625 loss : tensor(6.8025, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 89/625 loss : tensor(6.8718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 90/625 loss : tensor(6.7901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 91/625 loss : tensor(6.3723, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 92/625 loss : tensor(6.9488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 93/625 loss : tensor(6.7395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 94/625 loss : tensor(6.8143, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 95/625 loss : tensor(6.4917, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 96/625 loss : tensor(7.1183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 97/625 loss : tensor(6.8673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 98/625 loss : tensor(6.9888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 99/625 loss : tensor(6.5863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 100/625 loss : tensor(7.1016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 101/625 loss : tensor(6.6613, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 0 102/625 loss : tensor(6.9614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 103/625 loss : tensor(6.6083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 104/625 loss : tensor(6.7387, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 105/625 loss : tensor(7.0045, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 106/625 loss : tensor(7.4754, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 107/625 loss : tensor(7.0446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 108/625 loss : tensor(6.8761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 109/625 loss : tensor(7.7759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 110/625 loss : tensor(7.0460, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 111/625 loss : tensor(7.0575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 112/625 loss : tensor(7.0645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 113/625 loss : tensor(7.2238, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 114/625 loss : tensor(6.7405, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 115/625 loss : tensor(6.6367, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 116/625 loss : tensor(7.0403, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 117/625 loss : tensor(7.1462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 118/625 loss : tensor(6.7076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 119/625 loss : tensor(6.6261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 120/625 loss : tensor(6.8358, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 121/625 loss : tensor(6.6470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 122/625 loss : tensor(7.6474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 123/625 loss : tensor(6.6640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 124/625 loss : tensor(6.4315, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 125/625 loss : tensor(6.7566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 126/625 loss : tensor(7.3556, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 127/625 loss : tensor(7.1892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 128/625 loss : tensor(7.0554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 129/625 loss : tensor(7.0817, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 130/625 loss : tensor(6.4886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 131/625 loss : tensor(7.0525, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 132/625 loss : tensor(6.7580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 133/625 loss : tensor(7.5257, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 134/625 loss : tensor(7.1387, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 135/625 loss : tensor(7.0138, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 136/625 loss : tensor(7.1212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 137/625 loss : tensor(6.9470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 138/625 loss : tensor(7.5369, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 139/625 loss : tensor(6.8879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 140/625 loss : tensor(7.0235, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 141/625 loss : tensor(6.8928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 142/625 loss : tensor(6.9030, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 143/625 loss : tensor(6.5400, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 144/625 loss : tensor(6.9565, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 145/625 loss : tensor(6.9276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 146/625 loss : tensor(7.0770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 147/625 loss : tensor(7.2047, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 148/625 loss : tensor(7.0017, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 149/625 loss : tensor(6.5923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 150/625 loss : tensor(7.1834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 151/625 loss : tensor(6.6103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 152/625 loss : tensor(7.2170, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 153/625 loss : tensor(6.8867, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 154/625 loss : tensor(6.9009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 155/625 loss : tensor(6.8163, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 156/625 loss : tensor(7.0601, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 157/625 loss : tensor(6.7440, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 158/625 loss : tensor(7.2631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 159/625 loss : tensor(6.8909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 160/625 loss : tensor(6.6686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 161/625 loss : tensor(6.9578, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 162/625 loss : tensor(6.8135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 163/625 loss : tensor(6.8699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 164/625 loss : tensor(7.4782, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 165/625 loss : tensor(6.9995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 166/625 loss : tensor(7.2501, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 167/625 loss : tensor(6.5133, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 168/625 loss : tensor(6.6529, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 169/625 loss : tensor(6.9497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 大 庭 廣 眾 之 下 在 捷 運 摳 奶 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "target: 幹 ， 這 個 一 定 是 真 愛 ， 要 祝 福 好 嗎 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 0 170/625 loss : tensor(6.5621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 171/625 loss : tensor(7.2371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 172/625 loss : tensor(7.0402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 173/625 loss : tensor(7.3242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 瓦 男 去 做 長 照 是 不 是 很 爽 ? [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "target: 都 沒 人 回 ， 幫 [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "error.....\n",
      "target: 紅 蘿 蔔 蛋 的 主 體 是 紅 蘿 蔔 還 是 蛋 ？ [PAD] [PAD] [PAD] [PAD] \n",
      "target: 本 體 是 絲 不 切 絲 的 紅 蘿 波 根 本 不 能 吃 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 0 174/625 loss : tensor(6.9196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 175/625 loss : tensor(7.0876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 176/625 loss : tensor(6.7714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 177/625 loss : tensor(6.6818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 178/625 loss : tensor(7.1478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 179/625 loss : tensor(6.7850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 180/625 loss : tensor(6.6139, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 181/625 loss : tensor(7.4543, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 182/625 loss : tensor(6.7221, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 183/625 loss : tensor(6.9621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 184/625 loss : tensor(7.2663, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 185/625 loss : tensor(7.0771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 186/625 loss : tensor(7.0316, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 187/625 loss : tensor(6.8104, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 188/625 loss : tensor(6.8012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 189/625 loss : tensor(6.7638, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 190/625 loss : tensor(7.1451, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 191/625 loss : tensor(7.2161, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 192/625 loss : tensor(7.4282, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 193/625 loss : tensor(7.1355, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 194/625 loss : tensor(6.7306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 195/625 loss : tensor(6.6507, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 196/625 loss : tensor(6.8823, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 197/625 loss : tensor(6.9016, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 0 198/625 loss : tensor(6.7741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 199/625 loss : tensor(6.8281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 200/625 loss : tensor(6.9258, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 201/625 loss : tensor(6.6880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 202/625 loss : tensor(6.7769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 203/625 loss : tensor(6.6925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 204/625 loss : tensor(6.8381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 205/625 loss : tensor(6.8472, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 206/625 loss : tensor(7.2141, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 207/625 loss : tensor(7.4216, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 208/625 loss : tensor(6.6036, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 209/625 loss : tensor(6.9549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 210/625 loss : tensor(7.2261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 211/625 loss : tensor(6.9573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 212/625 loss : tensor(7.0569, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 213/625 loss : tensor(6.5539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 214/625 loss : tensor(7.0183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 215/625 loss : tensor(7.0753, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 216/625 loss : tensor(6.9809, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 217/625 loss : tensor(6.9926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 218/625 loss : tensor(7.1230, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 219/625 loss : tensor(7.0690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 220/625 loss : tensor(6.7627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 221/625 loss : tensor(6.9615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 222/625 loss : tensor(7.2098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 223/625 loss : tensor(6.7711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 224/625 loss : tensor(7.4304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 225/625 loss : tensor(7.2285, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 226/625 loss : tensor(6.7040, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 227/625 loss : tensor(6.6060, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 228/625 loss : tensor(6.7498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 229/625 loss : tensor(7.2902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 230/625 loss : tensor(6.7624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 231/625 loss : tensor(7.5434, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 232/625 loss : tensor(6.9200, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 233/625 loss : tensor(6.8334, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 234/625 loss : tensor(7.1113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 235/625 loss : tensor(6.9701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 236/625 loss : tensor(6.9502, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 237/625 loss : tensor(7.0859, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 238/625 loss : tensor(7.0073, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 239/625 loss : tensor(7.2308, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 240/625 loss : tensor(6.4146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 241/625 loss : tensor(7.1256, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 242/625 loss : tensor(6.6341, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 243/625 loss : tensor(6.8615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 244/625 loss : tensor(6.8974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 245/625 loss : tensor(7.0535, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 246/625 loss : tensor(6.6181, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 247/625 loss : tensor(7.0300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 248/625 loss : tensor(6.8229, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 249/625 loss : tensor(6.8120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 250/625 loss : tensor(7.0793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 251/625 loss : tensor(7.5155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 252/625 loss : tensor(6.8487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 253/625 loss : tensor(6.7766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 254/625 loss : tensor(6.9228, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 255/625 loss : tensor(7.0248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 256/625 loss : tensor(6.8899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 257/625 loss : tensor(6.4678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 258/625 loss : tensor(6.7152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 259/625 loss : tensor(6.9373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 260/625 loss : tensor(6.5743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 261/625 loss : tensor(7.1808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 262/625 loss : tensor(6.7292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 263/625 loss : tensor(7.0048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 264/625 loss : tensor(6.8776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 265/625 loss : tensor(6.8688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 266/625 loss : tensor(6.9878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 267/625 loss : tensor(7.3275, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 268/625 loss : tensor(6.5289, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 269/625 loss : tensor(6.9191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 270/625 loss : tensor(6.8835, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 271/625 loss : tensor(7.0597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 272/625 loss : tensor(7.0004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 273/625 loss : tensor(6.7347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 274/625 loss : tensor(7.2139, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 275/625 loss : tensor(6.9795, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 276/625 loss : tensor(6.8804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 277/625 loss : tensor(6.7591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 278/625 loss : tensor(6.7945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 279/625 loss : tensor(6.8379, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 280/625 loss : tensor(7.6657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 281/625 loss : tensor(6.9911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 282/625 loss : tensor(6.9141, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 283/625 loss : tensor(6.8310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 284/625 loss : tensor(6.5937, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 285/625 loss : tensor(6.8218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 286/625 loss : tensor(6.5883, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 287/625 loss : tensor(6.4482, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 288/625 loss : tensor(7.0029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 289/625 loss : tensor(6.6178, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 290/625 loss : tensor(6.7700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 291/625 loss : tensor(7.0083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 292/625 loss : tensor(6.7408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 293/625 loss : tensor(7.2958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 294/625 loss : tensor(7.4208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 295/625 loss : tensor(7.1368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 296/625 loss : tensor(6.9878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 297/625 loss : tensor(6.7512, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 298/625 loss : tensor(6.8590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 299/625 loss : tensor(7.1652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 300/625 loss : tensor(6.8937, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 0 301/625 loss : tensor(7.0390, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 302/625 loss : tensor(6.8327, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 303/625 loss : tensor(7.2119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 304/625 loss : tensor(7.1793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 305/625 loss : tensor(6.7810, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 306/625 loss : tensor(6.6684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 307/625 loss : tensor(6.9378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 308/625 loss : tensor(6.8061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 309/625 loss : tensor(6.7397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 310/625 loss : tensor(6.5090, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 311/625 loss : tensor(6.8479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 312/625 loss : tensor(6.7731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 313/625 loss : tensor(6.9180, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 314/625 loss : tensor(7.1424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 315/625 loss : tensor(7.0059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 316/625 loss : tensor(6.9560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 317/625 loss : tensor(6.4755, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 318/625 loss : tensor(7.0498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 319/625 loss : tensor(6.8661, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 320/625 loss : tensor(6.9468, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 321/625 loss : tensor(6.9555, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 322/625 loss : tensor(6.8077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 323/625 loss : tensor(7.0908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 324/625 loss : tensor(6.3609, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 325/625 loss : tensor(7.0760, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 326/625 loss : tensor(6.8922, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 327/625 loss : tensor(6.7658, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 328/625 loss : tensor(6.7641, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 329/625 loss : tensor(6.7297, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 330/625 loss : tensor(6.8155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 331/625 loss : tensor(7.0883, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 332/625 loss : tensor(7.1748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 333/625 loss : tensor(7.0718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 334/625 loss : tensor(7.2623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 335/625 loss : tensor(6.8659, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 336/625 loss : tensor(6.6341, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 337/625 loss : tensor(6.4965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 338/625 loss : tensor(6.5885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 339/625 loss : tensor(6.5193, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 340/625 loss : tensor(6.8959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 341/625 loss : tensor(7.0212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 342/625 loss : tensor(6.5848, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 遇 到 講 話 [UNK] 的 人 怎 麼 辦 ？ [PAD] [PAD] [PAD] [PAD] \n",
      "target: 有 比 八 卦 肥 宅 [UNK] 嗎 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 0 343/625 loss : tensor(6.8618, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 344/625 loss : tensor(7.1351, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 345/625 loss : tensor(7.1121, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 346/625 loss : tensor(6.7737, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 347/625 loss : tensor(7.0945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 348/625 loss : tensor(6.8971, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 349/625 loss : tensor(6.9153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 350/625 loss : tensor(6.6625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 351/625 loss : tensor(7.1189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 352/625 loss : tensor(6.7716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 353/625 loss : tensor(7.2137, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 354/625 loss : tensor(7.4709, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 355/625 loss : tensor(6.9513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 356/625 loss : tensor(6.8546, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 357/625 loss : tensor(7.2955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 358/625 loss : tensor(6.7884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 359/625 loss : tensor(7.3573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 360/625 loss : tensor(7.6517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 361/625 loss : tensor(6.9346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 362/625 loss : tensor(6.3401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 363/625 loss : tensor(6.8939, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 364/625 loss : tensor(7.4614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 365/625 loss : tensor(6.8697, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 366/625 loss : tensor(7.1707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 藍 瘦 香 菇 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "target: 用 這 梗 來 分 辨 智 商 真 的 很 好 用 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 0 367/625 loss : tensor(6.7947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 368/625 loss : tensor(6.7860, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 369/625 loss : tensor(7.1553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 370/625 loss : tensor(6.9464, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 371/625 loss : tensor(6.9006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 372/625 loss : tensor(7.0229, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 373/625 loss : tensor(6.9815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 374/625 loss : tensor(6.7856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 375/625 loss : tensor(6.6800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 376/625 loss : tensor(6.5505, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 377/625 loss : tensor(6.6004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 378/625 loss : tensor(6.6811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 379/625 loss : tensor(7.1605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 380/625 loss : tensor(6.9791, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 381/625 loss : tensor(7.5612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 382/625 loss : tensor(6.7304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 383/625 loss : tensor(7.2500, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 384/625 loss : tensor(7.0812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 385/625 loss : tensor(6.9499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 386/625 loss : tensor(6.6087, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 387/625 loss : tensor(7.0923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 388/625 loss : tensor(7.0059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 389/625 loss : tensor(6.9217, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 390/625 loss : tensor(6.6874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 391/625 loss : tensor(7.4270, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 392/625 loss : tensor(6.8397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 393/625 loss : tensor(6.5342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 394/625 loss : tensor(6.8808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 395/625 loss : tensor(6.6858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 396/625 loss : tensor(6.7838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 397/625 loss : tensor(6.8516, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 398/625 loss : tensor(6.6906, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 0 399/625 loss : tensor(7.1976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 400/625 loss : tensor(6.8766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 401/625 loss : tensor(7.0448, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 402/625 loss : tensor(6.9375, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 403/625 loss : tensor(6.9852, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 404/625 loss : tensor(7.1873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 405/625 loss : tensor(7.3761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 志 願 役 士 兵 罷 工 有 沒 有 搞 頭 ? [PAD] [PAD] [PAD] [PAD] \n",
      "target: 認 真 講 不 可 行 因 為 平 常 就 都 沒 在 做 事 幹 部 不 罷 工 都 沒 用 \n",
      "e : 0 406/625 loss : tensor(7.1163, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 407/625 loss : tensor(7.2544, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 408/625 loss : tensor(6.8829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 409/625 loss : tensor(6.9917, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 410/625 loss : tensor(6.8579, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 411/625 loss : tensor(7.1404, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 412/625 loss : tensor(7.1693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 413/625 loss : tensor(6.6585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 414/625 loss : tensor(6.5868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 415/625 loss : tensor(6.8710, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 416/625 loss : tensor(7.0030, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 417/625 loss : tensor(6.9709, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 418/625 loss : tensor(6.4557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 419/625 loss : tensor(6.8681, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 420/625 loss : tensor(7.0608, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 421/625 loss : tensor(6.9438, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 422/625 loss : tensor(6.8922, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 423/625 loss : tensor(6.9948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 424/625 loss : tensor(6.9848, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 425/625 loss : tensor(6.9905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 426/625 loss : tensor(6.9061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 427/625 loss : tensor(6.8585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 428/625 loss : tensor(6.6225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 429/625 loss : tensor(7.1236, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 430/625 loss : tensor(6.8246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 431/625 loss : tensor(6.9591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 432/625 loss : tensor(6.9532, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 433/625 loss : tensor(6.8580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 434/625 loss : tensor(7.5653, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 435/625 loss : tensor(6.8220, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 436/625 loss : tensor(6.7752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 437/625 loss : tensor(6.7672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 438/625 loss : tensor(7.0263, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 439/625 loss : tensor(7.0846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 440/625 loss : tensor(7.1569, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 441/625 loss : tensor(7.0199, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 442/625 loss : tensor(6.9223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 443/625 loss : tensor(6.5472, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 444/625 loss : tensor(7.1176, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 445/625 loss : tensor(6.8832, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 446/625 loss : tensor(6.8298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 447/625 loss : tensor(6.5465, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 448/625 loss : tensor(7.1714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 449/625 loss : tensor(6.8084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 450/625 loss : tensor(7.3353, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 451/625 loss : tensor(6.7504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 452/625 loss : tensor(6.8467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 453/625 loss : tensor(6.5975, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 454/625 loss : tensor(7.0332, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 455/625 loss : tensor(7.0565, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 456/625 loss : tensor(6.9114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 457/625 loss : tensor(6.8690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 458/625 loss : tensor(6.8355, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 459/625 loss : tensor(7.9058, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 460/625 loss : tensor(7.3214, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 461/625 loss : tensor(6.9963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 462/625 loss : tensor(6.7990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 463/625 loss : tensor(7.0101, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 464/625 loss : tensor(6.9106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 465/625 loss : tensor(7.1429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 466/625 loss : tensor(7.0487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 467/625 loss : tensor(6.8802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 468/625 loss : tensor(7.0182, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 469/625 loss : tensor(6.8449, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 470/625 loss : tensor(6.6315, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 471/625 loss : tensor(7.1492, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 472/625 loss : tensor(7.0379, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 473/625 loss : tensor(7.2187, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 474/625 loss : tensor(6.8699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 475/625 loss : tensor(6.7804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 476/625 loss : tensor(7.1492, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 477/625 loss : tensor(6.4253, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 478/625 loss : tensor(6.9945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 479/625 loss : tensor(6.9470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 480/625 loss : tensor(7.0434, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 481/625 loss : tensor(6.9701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 482/625 loss : tensor(6.8098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 483/625 loss : tensor(6.8949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 484/625 loss : tensor(6.7695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 485/625 loss : tensor(6.9185, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 486/625 loss : tensor(6.9140, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 487/625 loss : tensor(7.1522, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 488/625 loss : tensor(7.4337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 489/625 loss : tensor(7.1445, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 490/625 loss : tensor(6.6450, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 491/625 loss : tensor(7.0135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 492/625 loss : tensor(7.1229, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 0 L : tensor(6.9295, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Seq2Seq. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type TransBertEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type PositionalEncoding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type TransBertDecoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type GruEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type GruDecoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type DialogDNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 1 1/625 loss : tensor(6.5021, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 2/625 loss : tensor(6.9220, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 3/625 loss : tensor(7.1335, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 4/625 loss : tensor(7.3327, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 5/625 loss : tensor(7.4604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 6/625 loss : tensor(6.6294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 7/625 loss : tensor(7.3395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 8/625 loss : tensor(6.9647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 9/625 loss : tensor(6.9740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 10/625 loss : tensor(7.2192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 11/625 loss : tensor(6.9281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 12/625 loss : tensor(7.0730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 13/625 loss : tensor(7.1475, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 14/625 loss : tensor(6.5360, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 15/625 loss : tensor(6.9022, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 16/625 loss : tensor(7.0003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 17/625 loss : tensor(7.3990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 18/625 loss : tensor(6.7900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 19/625 loss : tensor(7.1150, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 20/625 loss : tensor(6.9728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 21/625 loss : tensor(6.8647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 22/625 loss : tensor(6.9868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 23/625 loss : tensor(7.1013, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 24/625 loss : tensor(6.8906, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 25/625 loss : tensor(7.0017, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 26/625 loss : tensor(7.1604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 27/625 loss : tensor(7.0050, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 28/625 loss : tensor(6.8219, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 29/625 loss : tensor(7.0985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 30/625 loss : tensor(6.8016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 31/625 loss : tensor(6.6144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 32/625 loss : tensor(6.7051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 33/625 loss : tensor(6.4038, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 34/625 loss : tensor(7.0604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 35/625 loss : tensor(6.7950, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 36/625 loss : tensor(6.9832, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 37/625 loss : tensor(6.7965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 38/625 loss : tensor(6.5925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 39/625 loss : tensor(7.0307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 40/625 loss : tensor(6.9603, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 41/625 loss : tensor(7.4801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 42/625 loss : tensor(7.1806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 43/625 loss : tensor(6.6499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 44/625 loss : tensor(6.9812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 45/625 loss : tensor(6.9183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 46/625 loss : tensor(7.0687, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 47/625 loss : tensor(6.7807, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 48/625 loss : tensor(6.5612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 49/625 loss : tensor(6.9995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 50/625 loss : tensor(6.8620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 51/625 loss : tensor(7.1239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 52/625 loss : tensor(7.2703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 53/625 loss : tensor(6.6432, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 54/625 loss : tensor(6.7763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 55/625 loss : tensor(6.6672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 56/625 loss : tensor(7.2381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 57/625 loss : tensor(6.4803, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 58/625 loss : tensor(7.0410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 59/625 loss : tensor(6.6633, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 60/625 loss : tensor(6.6842, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 61/625 loss : tensor(6.9842, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 62/625 loss : tensor(7.1983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 63/625 loss : tensor(7.3849, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 64/625 loss : tensor(6.9246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 65/625 loss : tensor(6.9196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 66/625 loss : tensor(6.7997, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 67/625 loss : tensor(6.9782, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 68/625 loss : tensor(6.5164, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 69/625 loss : tensor(6.9512, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 70/625 loss : tensor(6.9977, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 71/625 loss : tensor(6.5593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 72/625 loss : tensor(6.7910, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 73/625 loss : tensor(6.8650, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 74/625 loss : tensor(7.0549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 75/625 loss : tensor(7.2874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 76/625 loss : tensor(6.8325, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 77/625 loss : tensor(6.8752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 78/625 loss : tensor(6.7750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 79/625 loss : tensor(7.0744, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 80/625 loss : tensor(7.2135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 81/625 loss : tensor(6.5274, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 82/625 loss : tensor(7.0016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 83/625 loss : tensor(7.0422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 84/625 loss : tensor(6.9619, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 85/625 loss : tensor(6.5696, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 86/625 loss : tensor(6.9877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 87/625 loss : tensor(6.9000, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 88/625 loss : tensor(6.6068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 89/625 loss : tensor(7.0258, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 90/625 loss : tensor(7.0575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 91/625 loss : tensor(6.7900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 92/625 loss : tensor(6.8646, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 93/625 loss : tensor(6.5470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 94/625 loss : tensor(6.7815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 95/625 loss : tensor(6.7961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 96/625 loss : tensor(7.0818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 97/625 loss : tensor(6.8494, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 98/625 loss : tensor(7.2147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 99/625 loss : tensor(6.9833, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 100/625 loss : tensor(6.9500, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 101/625 loss : tensor(7.2436, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 102/625 loss : tensor(6.6516, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 103/625 loss : tensor(6.7712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 104/625 loss : tensor(6.9956, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 1 105/625 loss : tensor(6.7122, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 106/625 loss : tensor(6.9313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 107/625 loss : tensor(6.4441, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 108/625 loss : tensor(7.4888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 109/625 loss : tensor(6.6597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 110/625 loss : tensor(6.7598, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 111/625 loss : tensor(7.4437, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 112/625 loss : tensor(6.5585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 113/625 loss : tensor(6.8776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 114/625 loss : tensor(7.0595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 115/625 loss : tensor(6.9951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 116/625 loss : tensor(6.7630, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 117/625 loss : tensor(6.8450, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 118/625 loss : tensor(7.1268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 119/625 loss : tensor(7.2880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 120/625 loss : tensor(6.8314, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 121/625 loss : tensor(7.1182, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 122/625 loss : tensor(6.8680, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 123/625 loss : tensor(6.6897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 124/625 loss : tensor(6.8255, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 125/625 loss : tensor(7.0481, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 126/625 loss : tensor(6.9518, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 127/625 loss : tensor(6.9036, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 128/625 loss : tensor(6.9152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 129/625 loss : tensor(7.3572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 130/625 loss : tensor(6.9169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 131/625 loss : tensor(6.6370, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 132/625 loss : tensor(6.5983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 133/625 loss : tensor(7.1043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 134/625 loss : tensor(7.3718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 135/625 loss : tensor(7.0053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 136/625 loss : tensor(6.9579, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 137/625 loss : tensor(6.9704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 138/625 loss : tensor(6.7819, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 澤 野 泓 之 御 用 歌 姬 大 家 最 喜 歡 誰 ? [PAD] [PAD] [PAD] [PAD] \n",
      "target: 沒 復 原 啊 她 不 是 說 喉 嚨 有 腫 瘤 怕 會 影 [PAD] [PAD] [PAD] \n",
      "e : 1 139/625 loss : tensor(7.5439, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 140/625 loss : tensor(7.1333, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 141/625 loss : tensor(6.8873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 142/625 loss : tensor(6.8361, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 143/625 loss : tensor(7.0481, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 144/625 loss : tensor(6.7558, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 145/625 loss : tensor(6.8632, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 146/625 loss : tensor(7.2265, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 147/625 loss : tensor(6.9267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 148/625 loss : tensor(6.8398, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 149/625 loss : tensor(7.0917, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 150/625 loss : tensor(6.7662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 151/625 loss : tensor(6.7865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 152/625 loss : tensor(7.2463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 153/625 loss : tensor(6.8538, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 154/625 loss : tensor(6.7988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 155/625 loss : tensor(6.9412, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: [UNK] [UNK] 9 15 : 52 : 18 2018 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "target: 這 你 邏 輯 柯 這 樣 就 是 有 說 過 不 淹 水 阿 [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 1 156/625 loss : tensor(6.8321, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 157/625 loss : tensor(6.6974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 158/625 loss : tensor(6.7267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 159/625 loss : tensor(7.0603, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 160/625 loss : tensor(7.1001, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 161/625 loss : tensor(6.7535, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 162/625 loss : tensor(6.6451, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 163/625 loss : tensor(6.8948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 164/625 loss : tensor(7.4250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 165/625 loss : tensor(6.3265, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 166/625 loss : tensor(7.0839, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 167/625 loss : tensor(7.2542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 168/625 loss : tensor(6.8662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 169/625 loss : tensor(6.9423, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 170/625 loss : tensor(7.1260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 171/625 loss : tensor(7.1703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 172/625 loss : tensor(7.5398, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 173/625 loss : tensor(6.8421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 174/625 loss : tensor(6.8545, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 175/625 loss : tensor(7.0186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 176/625 loss : tensor(7.0971, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 177/625 loss : tensor(6.6732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 178/625 loss : tensor(7.3313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 179/625 loss : tensor(7.2588, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 180/625 loss : tensor(7.6446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 181/625 loss : tensor(6.8889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 182/625 loss : tensor(7.2686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 183/625 loss : tensor(7.2380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 184/625 loss : tensor(7.2338, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 185/625 loss : tensor(6.6824, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 186/625 loss : tensor(7.5820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 187/625 loss : tensor(6.9865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 188/625 loss : tensor(6.9248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 189/625 loss : tensor(6.7695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 190/625 loss : tensor(6.6378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 191/625 loss : tensor(6.8084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 192/625 loss : tensor(7.2312, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 193/625 loss : tensor(7.0598, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 194/625 loss : tensor(6.6256, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 195/625 loss : tensor(7.0138, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 196/625 loss : tensor(7.0854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 197/625 loss : tensor(6.9274, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 198/625 loss : tensor(7.3614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 199/625 loss : tensor(6.7964, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 200/625 loss : tensor(6.8691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 201/625 loss : tensor(6.8643, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 202/625 loss : tensor(6.8295, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 203/625 loss : tensor(6.8726, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 1 204/625 loss : tensor(6.8764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 205/625 loss : tensor(7.1254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 206/625 loss : tensor(6.7885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 207/625 loss : tensor(6.8491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 208/625 loss : tensor(7.0322, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 209/625 loss : tensor(6.4990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 210/625 loss : tensor(7.0226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 211/625 loss : tensor(6.5720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 212/625 loss : tensor(6.5796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 213/625 loss : tensor(6.7841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 214/625 loss : tensor(6.8606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 215/625 loss : tensor(7.1759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 216/625 loss : tensor(6.9123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 217/625 loss : tensor(7.3423, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 218/625 loss : tensor(6.6763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 219/625 loss : tensor(6.7270, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 220/625 loss : tensor(7.0346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 221/625 loss : tensor(6.6299, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 有 段 時 間 rc 出 現 個 人 叫 滷 蛋 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "target: 滷 蛋 ？ 去 看 他 直 播 啊 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 1 222/625 loss : tensor(6.9104, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 223/625 loss : tensor(6.3910, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 224/625 loss : tensor(6.5554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 225/625 loss : tensor(6.8363, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 226/625 loss : tensor(6.9902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 227/625 loss : tensor(7.3292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 228/625 loss : tensor(7.1339, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 229/625 loss : tensor(6.5989, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 230/625 loss : tensor(7.4008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 231/625 loss : tensor(6.9972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 232/625 loss : tensor(6.5684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 233/625 loss : tensor(6.7459, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 234/625 loss : tensor(6.5907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 235/625 loss : tensor(7.1652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 236/625 loss : tensor(6.6172, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 237/625 loss : tensor(6.7759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 238/625 loss : tensor(6.6479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 239/625 loss : tensor(7.0545, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 240/625 loss : tensor(6.5495, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 241/625 loss : tensor(6.6969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 242/625 loss : tensor(6.4640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 243/625 loss : tensor(7.2435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 244/625 loss : tensor(7.1465, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 245/625 loss : tensor(6.8732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 246/625 loss : tensor(6.9359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 247/625 loss : tensor(6.9569, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 248/625 loss : tensor(6.6237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 249/625 loss : tensor(7.1516, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 250/625 loss : tensor(7.0965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 251/625 loss : tensor(6.8318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 252/625 loss : tensor(6.7211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 253/625 loss : tensor(6.4094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 254/625 loss : tensor(6.7063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 255/625 loss : tensor(7.1687, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 256/625 loss : tensor(6.9055, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 257/625 loss : tensor(6.5386, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 258/625 loss : tensor(7.2901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 259/625 loss : tensor(7.1696, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 260/625 loss : tensor(6.6188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 有 沒 有 紅 白 機 版 [UNK] 的 八 卦 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "target: 紅 白 機 能 跑 這 個 ？ 硬 體 差 了 一 個 世 代 [PAD] [PAD] \n",
      "e : 1 261/625 loss : tensor(7.3599, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 262/625 loss : tensor(7.2954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 263/625 loss : tensor(7.2427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 264/625 loss : tensor(6.8529, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 265/625 loss : tensor(7.0700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 266/625 loss : tensor(7.0911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 267/625 loss : tensor(6.9620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 268/625 loss : tensor(6.8788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 269/625 loss : tensor(6.8560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 270/625 loss : tensor(6.6898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 271/625 loss : tensor(6.6923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 272/625 loss : tensor(6.6860, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 273/625 loss : tensor(6.9454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 274/625 loss : tensor(6.7637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 275/625 loss : tensor(6.6079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 276/625 loss : tensor(7.1369, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 277/625 loss : tensor(6.9540, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 278/625 loss : tensor(6.7185, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 279/625 loss : tensor(7.1480, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 280/625 loss : tensor(6.6688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 281/625 loss : tensor(7.0309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 282/625 loss : tensor(7.0698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 283/625 loss : tensor(6.6639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 284/625 loss : tensor(6.7168, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 285/625 loss : tensor(7.1374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 286/625 loss : tensor(7.3379, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 287/625 loss : tensor(6.7278, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 288/625 loss : tensor(6.8416, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 289/625 loss : tensor(6.7274, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 290/625 loss : tensor(7.2515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 291/625 loss : tensor(6.6918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 292/625 loss : tensor(7.1632, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 293/625 loss : tensor(6.8239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 294/625 loss : tensor(6.8501, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 295/625 loss : tensor(6.8792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 296/625 loss : tensor(6.6478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 297/625 loss : tensor(6.6472, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 298/625 loss : tensor(7.0039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 299/625 loss : tensor(7.2274, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 300/625 loss : tensor(6.8288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 301/625 loss : tensor(6.8521, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 302/625 loss : tensor(6.6442, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 1 303/625 loss : tensor(6.9732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 304/625 loss : tensor(7.1789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 305/625 loss : tensor(6.8477, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 306/625 loss : tensor(6.8409, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 307/625 loss : tensor(7.1421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 308/625 loss : tensor(7.1709, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 309/625 loss : tensor(7.2699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 310/625 loss : tensor(6.5404, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 311/625 loss : tensor(6.6609, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 312/625 loss : tensor(7.2849, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 313/625 loss : tensor(6.7024, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 314/625 loss : tensor(7.2270, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 315/625 loss : tensor(6.6824, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 316/625 loss : tensor(6.7670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 317/625 loss : tensor(6.8484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 318/625 loss : tensor(6.9620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 319/625 loss : tensor(7.0721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 主 動 幫 屁 股 吃 布 的 正 妹 拉 出 來 有 加 分 ㄇ [PAD] [PAD] \n",
      "target: 你 再 等 一 等 他 屁 股 吃 完 了 就 露 內 褲 了 傻 傻 的 [PAD] [PAD] [PAD] \n",
      "e : 1 320/625 loss : tensor(7.1135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 321/625 loss : tensor(6.9583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 322/625 loss : tensor(6.7173, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 323/625 loss : tensor(6.9500, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 324/625 loss : tensor(6.6956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 325/625 loss : tensor(6.7119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 326/625 loss : tensor(7.0560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 327/625 loss : tensor(7.0495, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 328/625 loss : tensor(6.9286, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 329/625 loss : tensor(7.0181, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 330/625 loss : tensor(7.3228, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 331/625 loss : tensor(7.1075, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 332/625 loss : tensor(6.9494, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 333/625 loss : tensor(6.7921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 334/625 loss : tensor(6.9290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 335/625 loss : tensor(7.0743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 336/625 loss : tensor(6.9102, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 337/625 loss : tensor(7.2367, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 338/625 loss : tensor(6.8081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 339/625 loss : tensor(6.9080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 340/625 loss : tensor(7.0686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 341/625 loss : tensor(6.4485, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 342/625 loss : tensor(6.8689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 343/625 loss : tensor(6.3724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 344/625 loss : tensor(6.8669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 345/625 loss : tensor(6.8228, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 346/625 loss : tensor(7.3733, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 347/625 loss : tensor(6.7622, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 348/625 loss : tensor(6.9435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 349/625 loss : tensor(6.9487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 350/625 loss : tensor(7.4192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 351/625 loss : tensor(6.7625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 352/625 loss : tensor(6.9135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 353/625 loss : tensor(7.1551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 354/625 loss : tensor(7.1515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 吳 寶 春 這 兩 天 的 作 為 是 不 是 有 高 人 指 點 ？ \n",
      "target: 不 是 高 人 ， 難 道 是 高 賽 ？ [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 1 355/625 loss : tensor(6.9634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 356/625 loss : tensor(7.1444, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 357/625 loss : tensor(7.0870, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 358/625 loss : tensor(7.1839, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 359/625 loss : tensor(6.8158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 360/625 loss : tensor(7.6743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 361/625 loss : tensor(6.8504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 362/625 loss : tensor(6.8934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 363/625 loss : tensor(6.3744, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 364/625 loss : tensor(6.6635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 365/625 loss : tensor(7.1289, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 366/625 loss : tensor(6.6531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 367/625 loss : tensor(6.7317, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 368/625 loss : tensor(7.1816, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 369/625 loss : tensor(6.5255, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 370/625 loss : tensor(7.0229, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 371/625 loss : tensor(6.5679, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 372/625 loss : tensor(6.9037, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 373/625 loss : tensor(7.0039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 374/625 loss : tensor(6.9353, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 375/625 loss : tensor(6.7753, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 376/625 loss : tensor(6.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 377/625 loss : tensor(7.0470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 378/625 loss : tensor(7.2784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 379/625 loss : tensor(7.2082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 380/625 loss : tensor(7.0521, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 381/625 loss : tensor(7.5421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 382/625 loss : tensor(7.0762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 383/625 loss : tensor(6.9855, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 384/625 loss : tensor(6.6961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 385/625 loss : tensor(6.5419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 386/625 loss : tensor(6.4445, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 387/625 loss : tensor(6.7736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 388/625 loss : tensor(7.0534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 389/625 loss : tensor(7.0965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 390/625 loss : tensor(6.7723, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 391/625 loss : tensor(7.5720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 392/625 loss : tensor(6.9978, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 393/625 loss : tensor(6.8874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 394/625 loss : tensor(7.6767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 395/625 loss : tensor(7.1225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 396/625 loss : tensor(7.5390, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 397/625 loss : tensor(6.7050, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 398/625 loss : tensor(7.1467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 399/625 loss : tensor(7.1270, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 400/625 loss : tensor(7.0720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 401/625 loss : tensor(6.8022, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 402/625 loss : tensor(6.8758, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 1 403/625 loss : tensor(6.4192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 404/625 loss : tensor(7.2382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 405/625 loss : tensor(6.6361, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 406/625 loss : tensor(6.8931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 407/625 loss : tensor(6.8883, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 408/625 loss : tensor(7.2113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 409/625 loss : tensor(7.0628, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 410/625 loss : tensor(6.9881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 411/625 loss : tensor(6.9800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 412/625 loss : tensor(6.8679, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 413/625 loss : tensor(7.1693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 414/625 loss : tensor(6.6277, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 415/625 loss : tensor(7.1683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 416/625 loss : tensor(6.6526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 417/625 loss : tensor(7.1570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 418/625 loss : tensor(6.7161, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 419/625 loss : tensor(6.5136, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 420/625 loss : tensor(7.1327, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 421/625 loss : tensor(7.2149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 422/625 loss : tensor(6.7755, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 423/625 loss : tensor(7.1566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 424/625 loss : tensor(6.8697, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 425/625 loss : tensor(6.8576, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 426/625 loss : tensor(7.1291, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 427/625 loss : tensor(6.7222, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 428/625 loss : tensor(6.6998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 429/625 loss : tensor(6.9279, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 430/625 loss : tensor(6.8815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 431/625 loss : tensor(6.4795, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 432/625 loss : tensor(6.5968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 433/625 loss : tensor(6.6895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 434/625 loss : tensor(6.8770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 435/625 loss : tensor(7.1616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 436/625 loss : tensor(6.6446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 437/625 loss : tensor(6.8076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 438/625 loss : tensor(7.0112, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 439/625 loss : tensor(7.1630, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 440/625 loss : tensor(7.1164, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 441/625 loss : tensor(6.5044, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 442/625 loss : tensor(6.6161, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 443/625 loss : tensor(6.9348, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 444/625 loss : tensor(7.0657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 445/625 loss : tensor(6.9799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 446/625 loss : tensor(6.7282, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 447/625 loss : tensor(7.4333, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 448/625 loss : tensor(7.1627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 449/625 loss : tensor(6.7247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 450/625 loss : tensor(6.3453, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 451/625 loss : tensor(7.1011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 452/625 loss : tensor(6.9474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 453/625 loss : tensor(6.4583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 454/625 loss : tensor(7.1008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 455/625 loss : tensor(6.7802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 456/625 loss : tensor(6.5368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 457/625 loss : tensor(7.4876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 458/625 loss : tensor(6.7941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 459/625 loss : tensor(7.1628, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 460/625 loss : tensor(6.8738, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 461/625 loss : tensor(6.8049, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 462/625 loss : tensor(6.7393, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 463/625 loss : tensor(6.9760, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 464/625 loss : tensor(7.2134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 465/625 loss : tensor(6.6058, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 466/625 loss : tensor(7.4580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 467/625 loss : tensor(6.7579, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 468/625 loss : tensor(6.9290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 469/625 loss : tensor(7.0083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 470/625 loss : tensor(6.6823, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 471/625 loss : tensor(6.8160, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 472/625 loss : tensor(7.5167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 473/625 loss : tensor(6.7189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 474/625 loss : tensor(7.2088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 475/625 loss : tensor(7.6872, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 476/625 loss : tensor(6.5646, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 477/625 loss : tensor(6.8596, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 478/625 loss : tensor(6.3166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 479/625 loss : tensor(7.0726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 480/625 loss : tensor(7.0480, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 481/625 loss : tensor(6.8944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 482/625 loss : tensor(7.3526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 483/625 loss : tensor(7.1835, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 484/625 loss : tensor(7.0467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 485/625 loss : tensor(6.6221, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 486/625 loss : tensor(6.8911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 487/625 loss : tensor(7.1551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 488/625 loss : tensor(7.1006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 489/625 loss : tensor(6.5762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 490/625 loss : tensor(6.9489, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 491/625 loss : tensor(7.0203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 492/625 loss : tensor(6.7983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 493/625 loss : tensor(7.1229, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 494/625 loss : tensor(6.7090, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 1 L : tensor(6.9312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "e : 2 1/625 loss : tensor(6.7350, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 2/625 loss : tensor(7.6228, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 3/625 loss : tensor(7.1762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 4/625 loss : tensor(6.7443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 5/625 loss : tensor(7.0213, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 6/625 loss : tensor(6.6373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 7/625 loss : tensor(7.2922, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 8/625 loss : tensor(6.8221, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 9/625 loss : tensor(7.1382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 10/625 loss : tensor(6.9137, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 2 11/625 loss : tensor(6.8615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 12/625 loss : tensor(6.0953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 13/625 loss : tensor(7.0873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 14/625 loss : tensor(6.9222, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 15/625 loss : tensor(6.7032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 16/625 loss : tensor(6.9669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 17/625 loss : tensor(7.0304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 18/625 loss : tensor(7.1591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 19/625 loss : tensor(7.1365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 有 甲 甲 是 被 女 森 傷 害 過 才 變 [UNK] 的 嗎 ？ [PAD] [PAD] [PAD] \n",
      "target: 有 ， 你 不 知 道 而 已 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 2 20/625 loss : tensor(6.8433, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 21/625 loss : tensor(7.5701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 22/625 loss : tensor(6.9347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 23/625 loss : tensor(6.5432, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 24/625 loss : tensor(7.2858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 25/625 loss : tensor(7.4034, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 26/625 loss : tensor(7.0240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 27/625 loss : tensor(6.9048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 28/625 loss : tensor(6.9899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 29/625 loss : tensor(7.1903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 30/625 loss : tensor(7.1163, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 31/625 loss : tensor(6.8152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 32/625 loss : tensor(6.8419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 33/625 loss : tensor(7.2011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 34/625 loss : tensor(6.9437, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 35/625 loss : tensor(7.1212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 36/625 loss : tensor(7.0407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 37/625 loss : tensor(6.6811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 38/625 loss : tensor(7.0595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 39/625 loss : tensor(6.8146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 40/625 loss : tensor(6.4431, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 41/625 loss : tensor(6.6048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 42/625 loss : tensor(6.7239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 43/625 loss : tensor(7.2538, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 44/625 loss : tensor(6.8066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 45/625 loss : tensor(6.5910, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 46/625 loss : tensor(7.0295, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 47/625 loss : tensor(6.9961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 48/625 loss : tensor(6.9980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 49/625 loss : tensor(6.7004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 50/625 loss : tensor(6.9343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 51/625 loss : tensor(6.8832, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 52/625 loss : tensor(7.1822, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 53/625 loss : tensor(7.2019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 54/625 loss : tensor(6.7815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 55/625 loss : tensor(6.8993, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 56/625 loss : tensor(7.2072, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 57/625 loss : tensor(7.0736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 58/625 loss : tensor(6.7202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 59/625 loss : tensor(7.0188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 60/625 loss : tensor(6.7373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 61/625 loss : tensor(6.9612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 62/625 loss : tensor(7.6349, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 63/625 loss : tensor(6.8281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 64/625 loss : tensor(6.6469, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 65/625 loss : tensor(6.9751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 66/625 loss : tensor(6.4342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 67/625 loss : tensor(6.7676, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 68/625 loss : tensor(6.5211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 69/625 loss : tensor(6.5751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 70/625 loss : tensor(7.0146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 71/625 loss : tensor(6.8876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 72/625 loss : tensor(7.0915, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 73/625 loss : tensor(6.6524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 74/625 loss : tensor(6.6867, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 75/625 loss : tensor(6.9318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 76/625 loss : tensor(7.1070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 77/625 loss : tensor(6.6152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 78/625 loss : tensor(7.0633, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 79/625 loss : tensor(6.6329, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 80/625 loss : tensor(7.0066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 81/625 loss : tensor(6.4949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 82/625 loss : tensor(7.0637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 83/625 loss : tensor(6.6226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 84/625 loss : tensor(6.9760, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 85/625 loss : tensor(6.6744, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 86/625 loss : tensor(6.9786, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 87/625 loss : tensor(6.9744, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 88/625 loss : tensor(7.4540, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 89/625 loss : tensor(7.1259, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 90/625 loss : tensor(6.7563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 91/625 loss : tensor(6.5980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 92/625 loss : tensor(6.8953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 93/625 loss : tensor(7.2594, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 94/625 loss : tensor(6.5978, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 95/625 loss : tensor(6.9179, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 96/625 loss : tensor(6.8828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 97/625 loss : tensor(7.0922, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 98/625 loss : tensor(6.3153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 99/625 loss : tensor(6.7642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 100/625 loss : tensor(6.6769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 101/625 loss : tensor(7.0669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 102/625 loss : tensor(7.0257, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 103/625 loss : tensor(6.8412, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 104/625 loss : tensor(7.0134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 105/625 loss : tensor(7.4618, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 106/625 loss : tensor(7.1100, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 107/625 loss : tensor(6.9077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 108/625 loss : tensor(6.8141, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 109/625 loss : tensor(6.7487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 110/625 loss : tensor(6.8455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 111/625 loss : tensor(6.8029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 112/625 loss : tensor(7.1996, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 2 113/625 loss : tensor(6.9587, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 114/625 loss : tensor(7.1006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 115/625 loss : tensor(7.2038, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 116/625 loss : tensor(6.8603, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 117/625 loss : tensor(6.9437, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 118/625 loss : tensor(7.1634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 119/625 loss : tensor(7.0268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 120/625 loss : tensor(6.6473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 121/625 loss : tensor(7.0845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 122/625 loss : tensor(7.1081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 123/625 loss : tensor(6.8316, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 124/625 loss : tensor(7.0268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 125/625 loss : tensor(7.1580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 126/625 loss : tensor(7.1942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 127/625 loss : tensor(7.5292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 128/625 loss : tensor(7.0088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 129/625 loss : tensor(7.3980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 130/625 loss : tensor(7.0173, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 131/625 loss : tensor(7.2645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 132/625 loss : tensor(6.9788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 133/625 loss : tensor(6.8512, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 134/625 loss : tensor(7.1790, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 135/625 loss : tensor(6.7532, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 136/625 loss : tensor(6.7504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 137/625 loss : tensor(6.8308, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 138/625 loss : tensor(6.4433, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 139/625 loss : tensor(7.0965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 140/625 loss : tensor(6.5833, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 141/625 loss : tensor(6.8828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 142/625 loss : tensor(6.8124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 143/625 loss : tensor(6.2954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 144/625 loss : tensor(7.0402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 145/625 loss : tensor(6.9205, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 146/625 loss : tensor(6.8496, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 147/625 loss : tensor(6.9051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 148/625 loss : tensor(6.9526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 149/625 loss : tensor(6.5225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 150/625 loss : tensor(6.6366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 151/625 loss : tensor(7.2429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 152/625 loss : tensor(6.9411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 153/625 loss : tensor(6.9366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 154/625 loss : tensor(6.5719, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 155/625 loss : tensor(7.3436, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 156/625 loss : tensor(6.7900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 157/625 loss : tensor(6.5928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 158/625 loss : tensor(7.1725, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 159/625 loss : tensor(6.8917, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 160/625 loss : tensor(6.8052, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 161/625 loss : tensor(6.9585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 162/625 loss : tensor(7.0645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 163/625 loss : tensor(6.7913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 164/625 loss : tensor(6.5529, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 165/625 loss : tensor(6.8024, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 166/625 loss : tensor(7.1563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 167/625 loss : tensor(7.2414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 168/625 loss : tensor(7.0164, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 169/625 loss : tensor(7.1596, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 170/625 loss : tensor(6.9435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 171/625 loss : tensor(6.5910, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 172/625 loss : tensor(6.6683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 173/625 loss : tensor(6.9322, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 174/625 loss : tensor(6.9478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 175/625 loss : tensor(6.8285, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 176/625 loss : tensor(7.0890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 177/625 loss : tensor(6.5652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 178/625 loss : tensor(7.1856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 179/625 loss : tensor(6.5788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 180/625 loss : tensor(6.8537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 181/625 loss : tensor(6.9365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 182/625 loss : tensor(6.5975, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 183/625 loss : tensor(6.6448, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 184/625 loss : tensor(6.8546, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 185/625 loss : tensor(6.5479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 186/625 loss : tensor(6.9008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 187/625 loss : tensor(7.2285, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: [UNK] 二 手 標 榜 女 用 是 加 分 還 扣 分 啊 ？ [PAD] [PAD] [PAD] \n",
      "target: 會 覺 得 女 用 機 比 較 不 會 摔 的 大 概 誤 會 什 麼 了 吧 [PAD] \n",
      "e : 2 188/625 loss : tensor(6.5366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 189/625 loss : tensor(6.5978, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 190/625 loss : tensor(6.9196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 191/625 loss : tensor(6.8196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 192/625 loss : tensor(6.8407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 193/625 loss : tensor(6.9612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 194/625 loss : tensor(6.6811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 195/625 loss : tensor(6.9993, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 196/625 loss : tensor(7.1178, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 197/625 loss : tensor(7.2436, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 198/625 loss : tensor(7.0307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 199/625 loss : tensor(6.6757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 200/625 loss : tensor(6.8516, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 201/625 loss : tensor(6.7737, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 202/625 loss : tensor(6.8137, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 203/625 loss : tensor(6.5923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 204/625 loss : tensor(6.7893, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 205/625 loss : tensor(7.0098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 206/625 loss : tensor(6.5582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 207/625 loss : tensor(6.9476, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 208/625 loss : tensor(6.6871, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 209/625 loss : tensor(7.0109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 210/625 loss : tensor(6.7677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 211/625 loss : tensor(6.8961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 212/625 loss : tensor(6.5478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 213/625 loss : tensor(6.9798, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 2 214/625 loss : tensor(6.8105, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 215/625 loss : tensor(6.7263, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 216/625 loss : tensor(6.3459, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 217/625 loss : tensor(6.8744, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 218/625 loss : tensor(6.4938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 219/625 loss : tensor(6.8174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 220/625 loss : tensor(7.4233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 221/625 loss : tensor(7.0270, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 222/625 loss : tensor(7.2044, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 223/625 loss : tensor(7.1209, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 224/625 loss : tensor(7.1518, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 225/625 loss : tensor(6.9470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 226/625 loss : tensor(7.4410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 227/625 loss : tensor(7.2753, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 228/625 loss : tensor(6.9750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 229/625 loss : tensor(6.2350, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 臉 很 跩 的 正 妹 穿 熱 褲 翹 腳 坐 在 小 7 外 ? [PAD] [PAD] \n",
      "target: 你 趕 快 尻 一 槍 妹 妹 就 會 回 到 電 腦 裡 了 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 2 230/625 loss : tensor(7.1028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 231/625 loss : tensor(6.5854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 232/625 loss : tensor(6.8879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 233/625 loss : tensor(7.0473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 234/625 loss : tensor(7.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 235/625 loss : tensor(6.9935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 236/625 loss : tensor(7.0574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 237/625 loss : tensor(6.8938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 238/625 loss : tensor(7.7395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 239/625 loss : tensor(6.9209, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 240/625 loss : tensor(7.1992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 241/625 loss : tensor(7.1674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 242/625 loss : tensor(7.0237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 243/625 loss : tensor(6.8305, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 244/625 loss : tensor(7.1816, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 245/625 loss : tensor(6.8924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 246/625 loss : tensor(6.3139, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 247/625 loss : tensor(7.1863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 248/625 loss : tensor(6.9456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 249/625 loss : tensor(7.0913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 250/625 loss : tensor(7.2741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 251/625 loss : tensor(7.2312, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 252/625 loss : tensor(6.7218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 253/625 loss : tensor(7.0154, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 254/625 loss : tensor(6.7663, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 255/625 loss : tensor(6.5743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 256/625 loss : tensor(7.0679, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 257/625 loss : tensor(6.6155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 258/625 loss : tensor(6.7766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 259/625 loss : tensor(6.7427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 260/625 loss : tensor(6.7746, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 261/625 loss : tensor(6.9389, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 262/625 loss : tensor(6.7224, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 263/625 loss : tensor(6.8287, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 264/625 loss : tensor(7.0582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 265/625 loss : tensor(7.1835, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 266/625 loss : tensor(6.8244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 267/625 loss : tensor(6.8524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 268/625 loss : tensor(6.7375, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 269/625 loss : tensor(6.7993, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 270/625 loss : tensor(7.3694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 271/625 loss : tensor(6.5175, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 272/625 loss : tensor(6.6164, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 273/625 loss : tensor(7.1408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 274/625 loss : tensor(6.9329, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 275/625 loss : tensor(6.9570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 276/625 loss : tensor(6.9443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 277/625 loss : tensor(6.6934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 278/625 loss : tensor(6.9309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 279/625 loss : tensor(7.5028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 280/625 loss : tensor(7.1820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 281/625 loss : tensor(7.2171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 282/625 loss : tensor(6.7979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 283/625 loss : tensor(7.1145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 284/625 loss : tensor(6.7194, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 285/625 loss : tensor(7.2178, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 286/625 loss : tensor(6.6836, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 287/625 loss : tensor(7.0487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 288/625 loss : tensor(6.8450, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 289/625 loss : tensor(7.4784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 290/625 loss : tensor(7.2235, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 291/625 loss : tensor(7.0759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 292/625 loss : tensor(6.8247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 293/625 loss : tensor(6.6411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 294/625 loss : tensor(6.7829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 295/625 loss : tensor(7.1607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 296/625 loss : tensor(7.0458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 297/625 loss : tensor(6.9537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 298/625 loss : tensor(7.1786, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 299/625 loss : tensor(7.2271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 300/625 loss : tensor(6.8826, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 301/625 loss : tensor(7.0785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 302/625 loss : tensor(6.8222, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 303/625 loss : tensor(6.5388, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 304/625 loss : tensor(6.4438, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 305/625 loss : tensor(6.8380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 306/625 loss : tensor(6.5700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 307/625 loss : tensor(7.0462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 308/625 loss : tensor(6.7790, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 309/625 loss : tensor(6.4795, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 310/625 loss : tensor(6.7179, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 311/625 loss : tensor(6.8736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 312/625 loss : tensor(6.9389, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 313/625 loss : tensor(7.3976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 314/625 loss : tensor(6.9956, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 2 315/625 loss : tensor(6.7792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 316/625 loss : tensor(6.7313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 317/625 loss : tensor(7.2233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 318/625 loss : tensor(7.0331, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 319/625 loss : tensor(6.8887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 320/625 loss : tensor(7.1727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 321/625 loss : tensor(6.7950, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 322/625 loss : tensor(6.6792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 323/625 loss : tensor(7.2157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 324/625 loss : tensor(7.3831, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 325/625 loss : tensor(6.8548, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 326/625 loss : tensor(7.4362, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 327/625 loss : tensor(7.3202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 328/625 loss : tensor(6.8708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 329/625 loss : tensor(7.2528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 330/625 loss : tensor(7.1646, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 331/625 loss : tensor(6.8415, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 332/625 loss : tensor(6.6560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 333/625 loss : tensor(6.9984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 334/625 loss : tensor(6.7799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 335/625 loss : tensor(7.3904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 336/625 loss : tensor(6.6525, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 337/625 loss : tensor(6.7286, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 338/625 loss : tensor(6.9625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 339/625 loss : tensor(7.0336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 340/625 loss : tensor(7.2045, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 341/625 loss : tensor(7.2986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 342/625 loss : tensor(6.8124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 343/625 loss : tensor(6.7547, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 344/625 loss : tensor(6.7467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 345/625 loss : tensor(6.6007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 346/625 loss : tensor(6.5497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 347/625 loss : tensor(6.8691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 348/625 loss : tensor(7.5513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 349/625 loss : tensor(6.7555, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 350/625 loss : tensor(7.2654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 351/625 loss : tensor(6.9010, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 352/625 loss : tensor(6.9921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 353/625 loss : tensor(6.9636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 354/625 loss : tensor(7.1123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 355/625 loss : tensor(6.9819, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 356/625 loss : tensor(6.7504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 357/625 loss : tensor(7.0248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 358/625 loss : tensor(7.2173, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 359/625 loss : tensor(7.2191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 360/625 loss : tensor(7.2936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 361/625 loss : tensor(7.1615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 362/625 loss : tensor(6.8243, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 363/625 loss : tensor(7.1241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 364/625 loss : tensor(7.2059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 365/625 loss : tensor(6.9369, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 366/625 loss : tensor(6.8298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 367/625 loss : tensor(6.8499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 368/625 loss : tensor(7.1778, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 369/625 loss : tensor(7.1329, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 370/625 loss : tensor(7.1869, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 371/625 loss : tensor(7.0063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 372/625 loss : tensor(7.6258, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 373/625 loss : tensor(6.8059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 374/625 loss : tensor(6.9160, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 375/625 loss : tensor(6.9677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 376/625 loss : tensor(7.2842, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 377/625 loss : tensor(6.9409, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 378/625 loss : tensor(6.8965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 379/625 loss : tensor(7.1554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 380/625 loss : tensor(7.1821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 381/625 loss : tensor(6.9168, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 382/625 loss : tensor(6.8380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 383/625 loss : tensor(7.2597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 384/625 loss : tensor(7.1306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 385/625 loss : tensor(6.8348, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 386/625 loss : tensor(6.2343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 387/625 loss : tensor(6.7220, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 388/625 loss : tensor(6.4302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 389/625 loss : tensor(6.8218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 390/625 loss : tensor(7.2523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 391/625 loss : tensor(6.7698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 392/625 loss : tensor(6.4728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 393/625 loss : tensor(6.9648, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 394/625 loss : tensor(7.0094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 395/625 loss : tensor(6.7454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 396/625 loss : tensor(6.8308, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 397/625 loss : tensor(6.7936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 398/625 loss : tensor(6.9577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 399/625 loss : tensor(6.9310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 400/625 loss : tensor(7.2888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 401/625 loss : tensor(6.9261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 402/625 loss : tensor(6.8428, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 403/625 loss : tensor(6.6646, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 404/625 loss : tensor(6.9903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 405/625 loss : tensor(6.8294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 406/625 loss : tensor(7.3981, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 407/625 loss : tensor(6.4791, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 408/625 loss : tensor(6.9763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 409/625 loss : tensor(6.5814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 410/625 loss : tensor(6.7317, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 411/625 loss : tensor(7.0101, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 412/625 loss : tensor(6.9706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 413/625 loss : tensor(6.4786, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 414/625 loss : tensor(6.8440, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 415/625 loss : tensor(6.7441, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 416/625 loss : tensor(6.9815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 417/625 loss : tensor(7.0247, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 2 418/625 loss : tensor(6.9733, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 419/625 loss : tensor(7.3505, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 420/625 loss : tensor(6.8626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 421/625 loss : tensor(7.4980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 422/625 loss : tensor(7.0736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 423/625 loss : tensor(6.7335, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 424/625 loss : tensor(7.1334, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 425/625 loss : tensor(6.7107, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 426/625 loss : tensor(7.0125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 427/625 loss : tensor(6.9195, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 428/625 loss : tensor(7.0932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 429/625 loss : tensor(6.7069, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 430/625 loss : tensor(6.5930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 431/625 loss : tensor(7.1275, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 432/625 loss : tensor(6.9781, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 433/625 loss : tensor(7.3155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 434/625 loss : tensor(6.4042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 435/625 loss : tensor(7.3039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 436/625 loss : tensor(7.3200, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 437/625 loss : tensor(7.0342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 438/625 loss : tensor(7.4227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 439/625 loss : tensor(7.1118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 440/625 loss : tensor(6.4347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 441/625 loss : tensor(6.7806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 442/625 loss : tensor(6.9843, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 443/625 loss : tensor(7.0437, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 444/625 loss : tensor(6.6814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 445/625 loss : tensor(7.3361, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 446/625 loss : tensor(6.9077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 447/625 loss : tensor(6.8024, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 448/625 loss : tensor(7.3421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 449/625 loss : tensor(6.7667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 450/625 loss : tensor(6.6050, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 451/625 loss : tensor(6.3749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 452/625 loss : tensor(6.8858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 453/625 loss : tensor(6.9172, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 454/625 loss : tensor(7.0019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 455/625 loss : tensor(6.9800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 456/625 loss : tensor(7.3631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 457/625 loss : tensor(6.6606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 458/625 loss : tensor(7.2029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 459/625 loss : tensor(7.0101, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 460/625 loss : tensor(7.2750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 461/625 loss : tensor(6.5307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 462/625 loss : tensor(7.0219, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 463/625 loss : tensor(6.7343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 464/625 loss : tensor(7.2260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 465/625 loss : tensor(6.8885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 466/625 loss : tensor(7.1113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 467/625 loss : tensor(6.8662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 468/625 loss : tensor(6.5485, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 469/625 loss : tensor(7.1720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 470/625 loss : tensor(6.7427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 471/625 loss : tensor(7.0300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 472/625 loss : tensor(6.9960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 473/625 loss : tensor(6.5499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 474/625 loss : tensor(6.7970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 475/625 loss : tensor(7.0752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 476/625 loss : tensor(7.0986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 477/625 loss : tensor(6.5934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 478/625 loss : tensor(6.7533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 479/625 loss : tensor(7.0131, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 480/625 loss : tensor(6.4267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 481/625 loss : tensor(7.1865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 482/625 loss : tensor(6.8948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 483/625 loss : tensor(6.8314, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 484/625 loss : tensor(6.7554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 485/625 loss : tensor(7.0186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 486/625 loss : tensor(7.2115, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 487/625 loss : tensor(6.7085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 488/625 loss : tensor(7.4302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 489/625 loss : tensor(6.9193, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 這 是 快 爆 炸 的 蟑 螂 嗎 ？ 求 解 ！ [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "target: 熱 水 淋 就 [UNK] 了 比 啥 小 肥 皂 水 好 用 多 了 [PAD] [PAD] [PAD] \n",
      "e : 2 490/625 loss : tensor(6.6240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 491/625 loss : tensor(6.9174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 492/625 loss : tensor(7.2326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 493/625 loss : tensor(6.9582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 494/625 loss : tensor(6.9938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 495/625 loss : tensor(6.7897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 496/625 loss : tensor(6.9414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 2 L : tensor(6.9311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "e : 3 1/625 loss : tensor(6.6274, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 2/625 loss : tensor(7.0511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 3/625 loss : tensor(6.6440, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 4/625 loss : tensor(6.6941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 5/625 loss : tensor(6.5912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 6/625 loss : tensor(7.3026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 7/625 loss : tensor(6.5557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 8/625 loss : tensor(7.0416, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 9/625 loss : tensor(6.6847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 10/625 loss : tensor(6.8978, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 11/625 loss : tensor(6.5557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 12/625 loss : tensor(6.7841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 13/625 loss : tensor(7.1602, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 14/625 loss : tensor(7.1280, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 15/625 loss : tensor(7.2751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 16/625 loss : tensor(6.7846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 17/625 loss : tensor(6.7437, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 18/625 loss : tensor(6.9899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 19/625 loss : tensor(7.3303, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 20/625 loss : tensor(6.6129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 21/625 loss : tensor(6.6825, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 22/625 loss : tensor(7.1380, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 3 23/625 loss : tensor(7.1521, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 24/625 loss : tensor(6.8707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 25/625 loss : tensor(6.6240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 26/625 loss : tensor(6.7494, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 27/625 loss : tensor(7.3502, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 28/625 loss : tensor(6.6453, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 29/625 loss : tensor(6.4944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 30/625 loss : tensor(6.8365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 31/625 loss : tensor(6.8966, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 32/625 loss : tensor(6.8383, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 33/625 loss : tensor(6.7586, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 34/625 loss : tensor(6.8002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 35/625 loss : tensor(6.9773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 36/625 loss : tensor(7.3676, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 37/625 loss : tensor(6.8326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 38/625 loss : tensor(7.0063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 39/625 loss : tensor(6.7589, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 40/625 loss : tensor(7.1232, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 41/625 loss : tensor(7.0649, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 42/625 loss : tensor(6.8139, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 43/625 loss : tensor(6.8562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 44/625 loss : tensor(6.6381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 45/625 loss : tensor(6.6949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 46/625 loss : tensor(7.0637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 47/625 loss : tensor(6.5476, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 48/625 loss : tensor(6.6975, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 49/625 loss : tensor(7.2635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 50/625 loss : tensor(7.3498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 51/625 loss : tensor(7.0925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 52/625 loss : tensor(6.9770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 53/625 loss : tensor(7.7304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 54/625 loss : tensor(7.1171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 55/625 loss : tensor(6.3850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 56/625 loss : tensor(7.1016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 57/625 loss : tensor(6.7281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 58/625 loss : tensor(7.1726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 59/625 loss : tensor(7.3337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 60/625 loss : tensor(6.8582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 61/625 loss : tensor(7.1170, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 62/625 loss : tensor(6.8702, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 63/625 loss : tensor(6.9984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 64/625 loss : tensor(6.9549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 65/625 loss : tensor(7.3514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 66/625 loss : tensor(6.5581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 67/625 loss : tensor(6.6484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 68/625 loss : tensor(6.7823, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 69/625 loss : tensor(7.3316, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 70/625 loss : tensor(7.0546, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 71/625 loss : tensor(6.8988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 72/625 loss : tensor(7.1723, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 73/625 loss : tensor(7.3709, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 74/625 loss : tensor(6.9410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 75/625 loss : tensor(6.9044, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 76/625 loss : tensor(6.5042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 77/625 loss : tensor(7.0811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 78/625 loss : tensor(7.1900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 79/625 loss : tensor(6.5440, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 80/625 loss : tensor(7.1798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 81/625 loss : tensor(7.4820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 82/625 loss : tensor(6.8321, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 83/625 loss : tensor(6.9062, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 84/625 loss : tensor(7.1670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 85/625 loss : tensor(7.0713, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 86/625 loss : tensor(6.8640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 87/625 loss : tensor(6.5880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 88/625 loss : tensor(7.1917, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 89/625 loss : tensor(6.7986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 90/625 loss : tensor(6.7653, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 91/625 loss : tensor(6.8800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 92/625 loss : tensor(6.9733, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 93/625 loss : tensor(6.6875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 94/625 loss : tensor(6.9603, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 95/625 loss : tensor(7.0245, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 96/625 loss : tensor(6.9804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 97/625 loss : tensor(6.7252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 98/625 loss : tensor(6.9179, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 99/625 loss : tensor(7.0820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 100/625 loss : tensor(6.4723, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 101/625 loss : tensor(6.9919, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 102/625 loss : tensor(6.7152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 103/625 loss : tensor(7.0030, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 104/625 loss : tensor(6.7028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 105/625 loss : tensor(6.8150, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 106/625 loss : tensor(7.4161, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 107/625 loss : tensor(6.8590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 108/625 loss : tensor(6.9535, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 109/625 loss : tensor(7.0508, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 110/625 loss : tensor(6.8988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 111/625 loss : tensor(6.9724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 112/625 loss : tensor(6.6416, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 113/625 loss : tensor(6.4562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 114/625 loss : tensor(7.0821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 115/625 loss : tensor(6.9416, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 116/625 loss : tensor(6.7517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 117/625 loss : tensor(7.2555, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 118/625 loss : tensor(6.8608, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 119/625 loss : tensor(7.0030, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 120/625 loss : tensor(6.9505, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 121/625 loss : tensor(6.9415, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 122/625 loss : tensor(6.9028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 123/625 loss : tensor(6.9037, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 124/625 loss : tensor(6.7805, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 125/625 loss : tensor(6.8514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 126/625 loss : tensor(6.6751, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 3 127/625 loss : tensor(7.0409, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 128/625 loss : tensor(6.8490, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 129/625 loss : tensor(7.1948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 130/625 loss : tensor(6.5625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 131/625 loss : tensor(7.1155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 132/625 loss : tensor(6.6142, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 133/625 loss : tensor(6.6627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 134/625 loss : tensor(6.5393, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 135/625 loss : tensor(6.9275, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 136/625 loss : tensor(7.0320, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 137/625 loss : tensor(6.3669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 138/625 loss : tensor(7.1534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 139/625 loss : tensor(6.6030, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 140/625 loss : tensor(7.1721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 141/625 loss : tensor(6.8350, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 142/625 loss : tensor(6.9384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 143/625 loss : tensor(7.0196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 144/625 loss : tensor(6.5364, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 145/625 loss : tensor(7.0772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 146/625 loss : tensor(7.4726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 147/625 loss : tensor(6.8899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 148/625 loss : tensor(6.6176, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 149/625 loss : tensor(7.5317, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 150/625 loss : tensor(6.6935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 151/625 loss : tensor(7.0844, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 152/625 loss : tensor(6.7507, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 153/625 loss : tensor(6.4614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 154/625 loss : tensor(6.8824, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 155/625 loss : tensor(6.8237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 156/625 loss : tensor(6.9536, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 157/625 loss : tensor(7.3968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 158/625 loss : tensor(6.8042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 159/625 loss : tensor(7.0011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 160/625 loss : tensor(6.8934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 161/625 loss : tensor(7.0198, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 162/625 loss : tensor(7.2571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 163/625 loss : tensor(6.8352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 164/625 loss : tensor(6.6285, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 165/625 loss : tensor(6.7250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 166/625 loss : tensor(6.8565, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 167/625 loss : tensor(6.7772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 168/625 loss : tensor(6.8672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 169/625 loss : tensor(6.9892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 170/625 loss : tensor(6.4633, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 171/625 loss : tensor(6.9436, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 172/625 loss : tensor(6.8561, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 173/625 loss : tensor(7.1377, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 174/625 loss : tensor(7.0445, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 175/625 loss : tensor(6.5487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 176/625 loss : tensor(7.2678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 177/625 loss : tensor(6.7533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 178/625 loss : tensor(7.1081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 179/625 loss : tensor(6.8855, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 180/625 loss : tensor(7.3839, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 181/625 loss : tensor(7.0365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 182/625 loss : tensor(6.6254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 183/625 loss : tensor(6.8651, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 184/625 loss : tensor(7.2556, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 185/625 loss : tensor(7.0342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 186/625 loss : tensor(6.9712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 187/625 loss : tensor(6.9620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 188/625 loss : tensor(6.9526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 189/625 loss : tensor(7.2026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 190/625 loss : tensor(6.4021, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 191/625 loss : tensor(6.6481, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 192/625 loss : tensor(7.2331, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 193/625 loss : tensor(7.5774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 194/625 loss : tensor(7.0865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 195/625 loss : tensor(6.6991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 196/625 loss : tensor(6.8913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 197/625 loss : tensor(6.8716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 198/625 loss : tensor(6.6112, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 199/625 loss : tensor(6.4073, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 200/625 loss : tensor(6.4597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 201/625 loss : tensor(6.5116, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 202/625 loss : tensor(6.9377, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 203/625 loss : tensor(7.0509, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 204/625 loss : tensor(6.8887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 205/625 loss : tensor(6.7666, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 206/625 loss : tensor(6.9144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 207/625 loss : tensor(7.0213, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 208/625 loss : tensor(6.6900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 209/625 loss : tensor(7.1096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 210/625 loss : tensor(6.3404, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 211/625 loss : tensor(7.3704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 212/625 loss : tensor(7.2811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 213/625 loss : tensor(6.8376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 214/625 loss : tensor(6.9194, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 215/625 loss : tensor(6.7117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 216/625 loss : tensor(6.7562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 217/625 loss : tensor(6.9778, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 218/625 loss : tensor(7.0696, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 219/625 loss : tensor(6.8967, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 220/625 loss : tensor(7.1167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 221/625 loss : tensor(6.8461, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 222/625 loss : tensor(7.2712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 223/625 loss : tensor(7.6427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 224/625 loss : tensor(7.2666, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 225/625 loss : tensor(6.5693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 桃 園 真 的 有 比 彰 雲 無 聊 ? [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "target: 應 該 說 桃 園 比 彰 雲 無 聊 你 是 哪 裡 聽 來 的 ？ [PAD] [PAD] [PAD] \n",
      "e : 3 226/625 loss : tensor(6.6738, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 227/625 loss : tensor(6.6926, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 3 228/625 loss : tensor(6.7916, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 229/625 loss : tensor(7.0606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 230/625 loss : tensor(6.9090, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 231/625 loss : tensor(6.3336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 232/625 loss : tensor(6.7325, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 233/625 loss : tensor(6.5269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 234/625 loss : tensor(7.2391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 235/625 loss : tensor(7.2781, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 236/625 loss : tensor(7.1114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 237/625 loss : tensor(6.9806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 238/625 loss : tensor(6.8997, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 239/625 loss : tensor(6.9634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 240/625 loss : tensor(6.6642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 241/625 loss : tensor(6.7260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 242/625 loss : tensor(7.6580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 243/625 loss : tensor(7.3776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 244/625 loss : tensor(6.4593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 還 沒 看 過 你 的 名 字 現 在 去 看 好 嗎 [PAD] [PAD] [PAD] \n",
      "target: 現 在 電 影 院 裡 平 均 年 齡 都 比 之 前 高 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 3 245/625 loss : tensor(6.9353, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 246/625 loss : tensor(6.9350, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 247/625 loss : tensor(6.8057, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 248/625 loss : tensor(6.4263, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 249/625 loss : tensor(7.2264, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 250/625 loss : tensor(7.8796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 251/625 loss : tensor(6.9840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 252/625 loss : tensor(6.6429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 253/625 loss : tensor(6.8631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 254/625 loss : tensor(6.7301, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 255/625 loss : tensor(6.9737, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 256/625 loss : tensor(6.9050, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 257/625 loss : tensor(6.9109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 258/625 loss : tensor(7.3448, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 259/625 loss : tensor(7.0614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 260/625 loss : tensor(7.2769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 261/625 loss : tensor(6.9450, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 262/625 loss : tensor(6.9120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 263/625 loss : tensor(7.4320, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 264/625 loss : tensor(6.8516, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 265/625 loss : tensor(6.7522, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 266/625 loss : tensor(7.0570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 267/625 loss : tensor(6.9966, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 268/625 loss : tensor(6.5907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 269/625 loss : tensor(6.9837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 270/625 loss : tensor(7.0319, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 271/625 loss : tensor(6.9538, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 272/625 loss : tensor(6.7732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 273/625 loss : tensor(6.9757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 274/625 loss : tensor(6.9793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 275/625 loss : tensor(6.5113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 276/625 loss : tensor(7.0711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 277/625 loss : tensor(7.3479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 278/625 loss : tensor(7.1793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 279/625 loss : tensor(6.7808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 280/625 loss : tensor(7.1385, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 281/625 loss : tensor(6.5203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 282/625 loss : tensor(6.6251, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 283/625 loss : tensor(6.8761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 284/625 loss : tensor(6.8743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 285/625 loss : tensor(6.9425, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 286/625 loss : tensor(7.0898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 287/625 loss : tensor(6.8294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 288/625 loss : tensor(7.3076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 289/625 loss : tensor(6.8221, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 290/625 loss : tensor(7.1866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 291/625 loss : tensor(7.1559, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 292/625 loss : tensor(6.8220, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 293/625 loss : tensor(6.8540, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 294/625 loss : tensor(7.0071, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 295/625 loss : tensor(6.6967, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 296/625 loss : tensor(6.5744, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 297/625 loss : tensor(6.7208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 298/625 loss : tensor(6.8578, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 299/625 loss : tensor(7.1112, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 300/625 loss : tensor(6.8670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 301/625 loss : tensor(6.8808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 302/625 loss : tensor(7.1239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 303/625 loss : tensor(6.7251, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 304/625 loss : tensor(6.9815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 305/625 loss : tensor(6.9276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 306/625 loss : tensor(7.1410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 307/625 loss : tensor(7.2808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 308/625 loss : tensor(7.1430, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 309/625 loss : tensor(6.6665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 310/625 loss : tensor(6.6631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 311/625 loss : tensor(6.8184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 312/625 loss : tensor(6.7853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 313/625 loss : tensor(7.3252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 314/625 loss : tensor(6.9015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 315/625 loss : tensor(6.8000, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 316/625 loss : tensor(6.5522, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 317/625 loss : tensor(6.9891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 318/625 loss : tensor(6.9881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 319/625 loss : tensor(6.8213, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 320/625 loss : tensor(6.9486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 321/625 loss : tensor(7.1927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 322/625 loss : tensor(6.8435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 323/625 loss : tensor(7.2518, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 324/625 loss : tensor(6.7444, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 325/625 loss : tensor(7.4825, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 326/625 loss : tensor(7.6089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 327/625 loss : tensor(6.8958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 328/625 loss : tensor(6.5577, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 3 329/625 loss : tensor(6.7082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 330/625 loss : tensor(7.0061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 331/625 loss : tensor(6.6082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 332/625 loss : tensor(6.9078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 333/625 loss : tensor(6.7248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 334/625 loss : tensor(6.6528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 335/625 loss : tensor(7.0876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 336/625 loss : tensor(6.7146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 337/625 loss : tensor(6.9251, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 338/625 loss : tensor(6.3667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 339/625 loss : tensor(6.8637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 340/625 loss : tensor(6.9354, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 341/625 loss : tensor(6.5863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 342/625 loss : tensor(7.0984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 343/625 loss : tensor(6.9597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 344/625 loss : tensor(6.9502, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 345/625 loss : tensor(6.4333, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 346/625 loss : tensor(7.2871, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 347/625 loss : tensor(6.7241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 348/625 loss : tensor(6.5252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 349/625 loss : tensor(7.0611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 350/625 loss : tensor(7.0725, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 351/625 loss : tensor(7.3943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 352/625 loss : tensor(6.5334, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 353/625 loss : tensor(6.8409, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 354/625 loss : tensor(6.9395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 355/625 loss : tensor(7.0780, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 356/625 loss : tensor(6.6646, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 357/625 loss : tensor(7.3515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 358/625 loss : tensor(6.9905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 359/625 loss : tensor(6.4667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 台 北 哪 家 飲 茶 最 好 吃 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "target: 我 朋 友 是 香 港 人 他 們 家 覺 得 那 間 還 算 道 地 [PAD] \n",
      "e : 3 360/625 loss : tensor(6.7863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 361/625 loss : tensor(6.6127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 362/625 loss : tensor(6.5225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 363/625 loss : tensor(7.0318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 364/625 loss : tensor(7.1847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 365/625 loss : tensor(7.0715, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 366/625 loss : tensor(6.6157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 七 七 七 七 七 七 起 來 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "target: 你 媽 的 差 有 夠 遠 去 自 盡 吧 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 3 367/625 loss : tensor(6.9550, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 368/625 loss : tensor(7.0652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 369/625 loss : tensor(6.8170, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 370/625 loss : tensor(7.1913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 371/625 loss : tensor(6.5084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 372/625 loss : tensor(7.0295, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 373/625 loss : tensor(7.1089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 374/625 loss : tensor(7.0393, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 375/625 loss : tensor(6.8991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 376/625 loss : tensor(7.2338, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 377/625 loss : tensor(7.2674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 378/625 loss : tensor(6.3293, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 379/625 loss : tensor(7.0315, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 380/625 loss : tensor(6.5327, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 381/625 loss : tensor(6.9252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 382/625 loss : tensor(7.1320, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 383/625 loss : tensor(7.1577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 384/625 loss : tensor(6.8670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 385/625 loss : tensor(6.9527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 386/625 loss : tensor(6.7087, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 387/625 loss : tensor(7.1232, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 388/625 loss : tensor(6.7494, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 389/625 loss : tensor(7.3614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 390/625 loss : tensor(7.3769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 391/625 loss : tensor(6.8999, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 392/625 loss : tensor(7.3333, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 393/625 loss : tensor(6.8740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 394/625 loss : tensor(6.7330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 395/625 loss : tensor(7.3053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 396/625 loss : tensor(7.0444, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 397/625 loss : tensor(6.2979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 398/625 loss : tensor(6.7894, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 399/625 loss : tensor(6.6911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 400/625 loss : tensor(7.2990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 401/625 loss : tensor(6.9584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 402/625 loss : tensor(6.4302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 403/625 loss : tensor(6.8550, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 404/625 loss : tensor(6.8519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 405/625 loss : tensor(7.1257, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 406/625 loss : tensor(7.0075, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 407/625 loss : tensor(7.3411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 408/625 loss : tensor(6.6202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 409/625 loss : tensor(7.2737, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 410/625 loss : tensor(6.9634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 411/625 loss : tensor(7.1324, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 412/625 loss : tensor(7.1895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 413/625 loss : tensor(7.1925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 414/625 loss : tensor(6.7070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 415/625 loss : tensor(7.0402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 416/625 loss : tensor(7.3759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 417/625 loss : tensor(6.7847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 418/625 loss : tensor(7.5797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 419/625 loss : tensor(6.9170, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 420/625 loss : tensor(7.2021, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 說 自 己 4 千 人 斬 der 女 森 在 想 什 麼 ? o ' _ ' o \n",
      "target: 一 天 斬 一 個 ， 4 千 人 起 碼 也 要 斬 快 11 年 才 斬 的 完 。 \n",
      "e : 3 421/625 loss : tensor(7.0035, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 422/625 loss : tensor(6.4636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 423/625 loss : tensor(6.9482, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 424/625 loss : tensor(6.9366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 425/625 loss : tensor(6.7222, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 3 426/625 loss : tensor(6.7326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 427/625 loss : tensor(6.4070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 428/625 loss : tensor(6.7218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 429/625 loss : tensor(7.0126, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 430/625 loss : tensor(6.7226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 431/625 loss : tensor(6.6419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 432/625 loss : tensor(6.9699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 433/625 loss : tensor(7.4059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 434/625 loss : tensor(6.8947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 435/625 loss : tensor(6.9585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 436/625 loss : tensor(7.1301, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 437/625 loss : tensor(6.8943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 438/625 loss : tensor(6.6931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 439/625 loss : tensor(7.0821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 440/625 loss : tensor(7.2116, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 441/625 loss : tensor(6.8532, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 442/625 loss : tensor(6.7800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 443/625 loss : tensor(6.8548, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 444/625 loss : tensor(6.8634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 445/625 loss : tensor(7.0118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 446/625 loss : tensor(6.8815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 447/625 loss : tensor(6.8220, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 448/625 loss : tensor(6.7802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 449/625 loss : tensor(7.2325, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 450/625 loss : tensor(6.8773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 451/625 loss : tensor(6.7607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 452/625 loss : tensor(6.8376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 453/625 loss : tensor(7.1160, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 454/625 loss : tensor(6.7995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 455/625 loss : tensor(6.8042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 456/625 loss : tensor(7.1572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 457/625 loss : tensor(7.1642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 458/625 loss : tensor(6.8523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 459/625 loss : tensor(7.0572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 460/625 loss : tensor(7.1008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 461/625 loss : tensor(7.3324, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 462/625 loss : tensor(6.7906, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 463/625 loss : tensor(6.9785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 464/625 loss : tensor(6.9819, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 465/625 loss : tensor(6.7518, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 466/625 loss : tensor(6.8399, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 467/625 loss : tensor(6.7168, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 468/625 loss : tensor(7.2799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 469/625 loss : tensor(7.5033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 470/625 loss : tensor(7.0145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 471/625 loss : tensor(7.1172, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 472/625 loss : tensor(7.1690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 473/625 loss : tensor(6.9646, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 474/625 loss : tensor(6.5479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 475/625 loss : tensor(6.6790, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 476/625 loss : tensor(6.7708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 477/625 loss : tensor(6.8820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 478/625 loss : tensor(7.0214, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 479/625 loss : tensor(6.5863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 480/625 loss : tensor(7.1309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 481/625 loss : tensor(7.3135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 482/625 loss : tensor(6.9076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 483/625 loss : tensor(6.9853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 484/625 loss : tensor(6.8059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 485/625 loss : tensor(6.7255, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 486/625 loss : tensor(7.0936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 487/625 loss : tensor(6.8421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 488/625 loss : tensor(7.1437, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 489/625 loss : tensor(6.9616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 490/625 loss : tensor(6.9407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 491/625 loss : tensor(6.9456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 492/625 loss : tensor(6.5456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 493/625 loss : tensor(7.4746, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 3 494/625 loss : tensor(6.7603, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 妹 子 緹 塔 會 領 便 當 嗎 ☺ [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "target: 4 王 子 快 去 死 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 3 L : tensor(6.9263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "e : 4 1/625 loss : tensor(6.6844, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 2/625 loss : tensor(6.6567, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 3/625 loss : tensor(6.6434, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 大 陸 人 為 了 醫 療 資 源 留 在 台 灣 ？ [PAD] [PAD] \n",
      "target: 人 看 ， 台 灣 還 有 很 多 偏 鄉 應 該 要 優 先 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 4 4/625 loss : tensor(6.6371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 5/625 loss : tensor(6.6442, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 6/625 loss : tensor(7.1455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 7/625 loss : tensor(7.2935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 8/625 loss : tensor(7.3350, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 9/625 loss : tensor(6.8335, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 10/625 loss : tensor(6.7377, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 11/625 loss : tensor(7.2246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 12/625 loss : tensor(6.5656, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 13/625 loss : tensor(7.0893, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 14/625 loss : tensor(7.3642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 15/625 loss : tensor(6.9169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 16/625 loss : tensor(7.3670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 17/625 loss : tensor(6.6131, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 18/625 loss : tensor(7.2498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 19/625 loss : tensor(6.8076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 20/625 loss : tensor(7.4935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 21/625 loss : tensor(7.0007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 22/625 loss : tensor(6.6887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 23/625 loss : tensor(6.8664, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 24/625 loss : tensor(7.3526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 25/625 loss : tensor(6.8029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 26/625 loss : tensor(7.5456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 27/625 loss : tensor(7.1843, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 28/625 loss : tensor(6.5936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 29/625 loss : tensor(7.0173, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 4 30/625 loss : tensor(6.7614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 31/625 loss : tensor(6.9963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 32/625 loss : tensor(7.0675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 33/625 loss : tensor(6.6310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 34/625 loss : tensor(6.7151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 35/625 loss : tensor(6.7451, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 36/625 loss : tensor(7.1476, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 37/625 loss : tensor(6.7531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 38/625 loss : tensor(7.2929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 39/625 loss : tensor(7.1619, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 40/625 loss : tensor(7.4402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 41/625 loss : tensor(7.1180, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 42/625 loss : tensor(6.9271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 43/625 loss : tensor(6.9011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 44/625 loss : tensor(6.8545, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 45/625 loss : tensor(7.0536, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 46/625 loss : tensor(6.9788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 47/625 loss : tensor(6.9570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 48/625 loss : tensor(6.9535, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 49/625 loss : tensor(6.8570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 50/625 loss : tensor(6.6957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 51/625 loss : tensor(7.0763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 52/625 loss : tensor(7.3873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 53/625 loss : tensor(6.8606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 4 個 屁 孩 疑 似 吸 毒 ？ [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "target: 會 不 會 搞 到 最 後 租 車 公 司 大 7 車 主 有 插 股 [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 4 54/625 loss : tensor(7.2854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 55/625 loss : tensor(7.2644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 56/625 loss : tensor(7.1310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 57/625 loss : tensor(6.7145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 58/625 loss : tensor(6.6536, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 有 沒 有 愛 莉 戴 眼 鏡 的 八 卦 ? [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "target: 明 明 就 日 向 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 4 59/625 loss : tensor(6.5284, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 60/625 loss : tensor(7.2488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 61/625 loss : tensor(6.6621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 62/625 loss : tensor(6.6059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 63/625 loss : tensor(6.8273, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 64/625 loss : tensor(6.7430, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 65/625 loss : tensor(6.8300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 66/625 loss : tensor(6.7496, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 67/625 loss : tensor(6.8132, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 68/625 loss : tensor(6.6212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 69/625 loss : tensor(7.1022, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 70/625 loss : tensor(7.3885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 71/625 loss : tensor(6.8006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 72/625 loss : tensor(6.7474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 73/625 loss : tensor(6.7989, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 74/625 loss : tensor(6.9613, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 75/625 loss : tensor(6.9418, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 76/625 loss : tensor(6.8026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 77/625 loss : tensor(7.0334, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 78/625 loss : tensor(6.6611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 79/625 loss : tensor(7.1473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 80/625 loss : tensor(6.7934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 81/625 loss : tensor(7.2189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 82/625 loss : tensor(7.3938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 83/625 loss : tensor(7.0058, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 84/625 loss : tensor(6.8820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 85/625 loss : tensor(7.1027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 86/625 loss : tensor(6.7643, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 87/625 loss : tensor(6.7813, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 88/625 loss : tensor(6.9614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 89/625 loss : tensor(6.7706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 90/625 loss : tensor(6.9276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 91/625 loss : tensor(6.5181, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 92/625 loss : tensor(6.8237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 93/625 loss : tensor(6.5911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 94/625 loss : tensor(7.0368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 95/625 loss : tensor(7.4763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 96/625 loss : tensor(6.7906, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 97/625 loss : tensor(7.0326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 98/625 loss : tensor(7.2167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 99/625 loss : tensor(6.8313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 100/625 loss : tensor(7.2783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 101/625 loss : tensor(6.4847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 102/625 loss : tensor(6.3587, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 103/625 loss : tensor(7.0467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 104/625 loss : tensor(7.1447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 105/625 loss : tensor(6.7196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 106/625 loss : tensor(6.7163, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 107/625 loss : tensor(6.7674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 108/625 loss : tensor(6.8609, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 109/625 loss : tensor(6.7912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 110/625 loss : tensor(6.9136, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 111/625 loss : tensor(6.8968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 112/625 loss : tensor(6.9027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 113/625 loss : tensor(7.0716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 114/625 loss : tensor(6.6850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 115/625 loss : tensor(7.3112, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 116/625 loss : tensor(6.9948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 117/625 loss : tensor(6.7613, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 118/625 loss : tensor(6.9938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 119/625 loss : tensor(6.8226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 120/625 loss : tensor(7.0639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 121/625 loss : tensor(6.4407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 122/625 loss : tensor(7.1377, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 123/625 loss : tensor(6.7569, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 124/625 loss : tensor(7.2350, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 125/625 loss : tensor(7.0135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 126/625 loss : tensor(6.4155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 127/625 loss : tensor(7.1125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 128/625 loss : tensor(6.7582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 129/625 loss : tensor(7.0779, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 4 130/625 loss : tensor(6.5467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 131/625 loss : tensor(6.9681, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 132/625 loss : tensor(7.0499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 133/625 loss : tensor(6.8583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 134/625 loss : tensor(7.2291, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 135/625 loss : tensor(6.6435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 136/625 loss : tensor(7.0897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 137/625 loss : tensor(7.0418, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 138/625 loss : tensor(6.9909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 139/625 loss : tensor(6.8604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 140/625 loss : tensor(7.4128, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 141/625 loss : tensor(7.3078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 142/625 loss : tensor(6.9488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 143/625 loss : tensor(6.5932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 144/625 loss : tensor(7.2949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 145/625 loss : tensor(7.0549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 146/625 loss : tensor(7.2805, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 147/625 loss : tensor(6.7212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 148/625 loss : tensor(7.0812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 149/625 loss : tensor(7.0377, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 150/625 loss : tensor(7.0469, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 151/625 loss : tensor(6.8669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 152/625 loss : tensor(6.6789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 153/625 loss : tensor(6.6919, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 154/625 loss : tensor(6.9456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 155/625 loss : tensor(7.2257, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 156/625 loss : tensor(7.1476, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 157/625 loss : tensor(7.0808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 158/625 loss : tensor(6.8699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 159/625 loss : tensor(6.8787, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 160/625 loss : tensor(7.6243, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 161/625 loss : tensor(6.9753, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 162/625 loss : tensor(7.5860, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 163/625 loss : tensor(7.1805, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 164/625 loss : tensor(7.0623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 165/625 loss : tensor(7.5296, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 166/625 loss : tensor(7.0355, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 167/625 loss : tensor(6.7395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 168/625 loss : tensor(6.9931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 169/625 loss : tensor(6.8625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 170/625 loss : tensor(6.7398, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 171/625 loss : tensor(6.8593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 172/625 loss : tensor(7.0675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 173/625 loss : tensor(7.4549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 174/625 loss : tensor(6.5625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 175/625 loss : tensor(7.1515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 176/625 loss : tensor(6.4628, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 177/625 loss : tensor(6.8490, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 178/625 loss : tensor(6.5819, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 179/625 loss : tensor(6.6825, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 180/625 loss : tensor(6.9177, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 181/625 loss : tensor(6.5997, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 182/625 loss : tensor(6.9275, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 183/625 loss : tensor(7.5187, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 184/625 loss : tensor(6.9710, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 185/625 loss : tensor(6.4894, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 186/625 loss : tensor(6.9791, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 187/625 loss : tensor(7.1895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 188/625 loss : tensor(6.7785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 189/625 loss : tensor(7.3655, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 190/625 loss : tensor(7.3157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 191/625 loss : tensor(6.4275, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 192/625 loss : tensor(6.8975, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 193/625 loss : tensor(6.8069, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 194/625 loss : tensor(6.6956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 195/625 loss : tensor(6.9607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 196/625 loss : tensor(6.7935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 197/625 loss : tensor(6.6336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 198/625 loss : tensor(6.7929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 199/625 loss : tensor(6.5285, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 200/625 loss : tensor(6.8755, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 201/625 loss : tensor(6.5856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 202/625 loss : tensor(6.8424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 203/625 loss : tensor(6.8600, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 204/625 loss : tensor(6.9274, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 205/625 loss : tensor(6.7789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 206/625 loss : tensor(6.9939, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 207/625 loss : tensor(6.7725, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 208/625 loss : tensor(7.1449, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 209/625 loss : tensor(6.7864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 210/625 loss : tensor(6.8966, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 211/625 loss : tensor(6.9892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 212/625 loss : tensor(6.9326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 213/625 loss : tensor(6.7401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 214/625 loss : tensor(6.5690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 215/625 loss : tensor(7.2495, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 216/625 loss : tensor(7.6028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 217/625 loss : tensor(6.5848, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 218/625 loss : tensor(7.1759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 219/625 loss : tensor(6.8573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 220/625 loss : tensor(6.3733, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 221/625 loss : tensor(7.1053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 222/625 loss : tensor(6.8735, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 223/625 loss : tensor(6.9294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 224/625 loss : tensor(6.8063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 225/625 loss : tensor(6.8313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 226/625 loss : tensor(6.9523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 227/625 loss : tensor(6.7763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 228/625 loss : tensor(6.9544, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 229/625 loss : tensor(6.8391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 230/625 loss : tensor(6.7042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 231/625 loss : tensor(6.5540, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 232/625 loss : tensor(7.2652, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 4 233/625 loss : tensor(7.0583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 234/625 loss : tensor(7.1648, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 235/625 loss : tensor(6.9150, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 236/625 loss : tensor(6.7480, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 237/625 loss : tensor(6.5896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 238/625 loss : tensor(7.0469, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 239/625 loss : tensor(7.3577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 240/625 loss : tensor(7.0544, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 241/625 loss : tensor(6.8878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 242/625 loss : tensor(6.9193, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 243/625 loss : tensor(6.9994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 244/625 loss : tensor(7.3259, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 245/625 loss : tensor(7.2603, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 246/625 loss : tensor(6.6346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 247/625 loss : tensor(6.6993, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 248/625 loss : tensor(6.9749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 249/625 loss : tensor(6.7245, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 250/625 loss : tensor(6.8850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 251/625 loss : tensor(6.8991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 252/625 loss : tensor(6.6948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 253/625 loss : tensor(6.9725, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 254/625 loss : tensor(6.8822, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 255/625 loss : tensor(6.5661, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 256/625 loss : tensor(7.1216, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 257/625 loss : tensor(6.6861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 258/625 loss : tensor(7.1971, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 259/625 loss : tensor(7.1753, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 260/625 loss : tensor(6.9183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 261/625 loss : tensor(6.9253, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 262/625 loss : tensor(6.8547, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 263/625 loss : tensor(7.1604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 264/625 loss : tensor(6.9185, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 265/625 loss : tensor(6.5258, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 266/625 loss : tensor(7.2085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 267/625 loss : tensor(6.4782, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 268/625 loss : tensor(6.9989, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 蘋 果 工 程 師 看 到 網 路 酸 民 會 難 過 嗎 \n",
      "target: 難 道 你 要 買 安 卓 垃 圾 ？ [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 4 269/625 loss : tensor(7.0677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 270/625 loss : tensor(6.7562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 271/625 loss : tensor(6.4657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 272/625 loss : tensor(7.0334, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 273/625 loss : tensor(6.6336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 274/625 loss : tensor(7.0669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 275/625 loss : tensor(6.9221, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 276/625 loss : tensor(7.1326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 277/625 loss : tensor(6.5365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 278/625 loss : tensor(6.7571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 279/625 loss : tensor(6.7957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 280/625 loss : tensor(7.2484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 281/625 loss : tensor(6.8565, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 282/625 loss : tensor(7.0819, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 283/625 loss : tensor(6.6754, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 284/625 loss : tensor(6.7904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 285/625 loss : tensor(6.5767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 286/625 loss : tensor(7.5197, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 287/625 loss : tensor(7.1666, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 288/625 loss : tensor(6.6296, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 289/625 loss : tensor(7.4895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 290/625 loss : tensor(6.7569, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 291/625 loss : tensor(6.5285, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 292/625 loss : tensor(7.7223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 293/625 loss : tensor(6.5384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 294/625 loss : tensor(6.5443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 295/625 loss : tensor(6.9699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 296/625 loss : tensor(6.9020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 297/625 loss : tensor(6.8129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 298/625 loss : tensor(6.6491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 299/625 loss : tensor(6.7388, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 300/625 loss : tensor(6.7503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 301/625 loss : tensor(7.3212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 302/625 loss : tensor(6.8413, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 303/625 loss : tensor(6.5686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 304/625 loss : tensor(6.7365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 305/625 loss : tensor(6.6167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 306/625 loss : tensor(7.2052, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 307/625 loss : tensor(7.2867, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 308/625 loss : tensor(6.8642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 309/625 loss : tensor(7.1265, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 310/625 loss : tensor(6.8753, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 311/625 loss : tensor(6.9159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 312/625 loss : tensor(6.8225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 313/625 loss : tensor(6.7957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 314/625 loss : tensor(6.7103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 315/625 loss : tensor(6.4676, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 316/625 loss : tensor(6.6706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 317/625 loss : tensor(7.3639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 318/625 loss : tensor(6.8905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 319/625 loss : tensor(6.4624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 320/625 loss : tensor(6.9765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 321/625 loss : tensor(6.8172, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 322/625 loss : tensor(6.6406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 323/625 loss : tensor(6.7918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 今 年 台 灣 年 度 代 表 的 經 典 名 言 是 ？ [PAD] [PAD] [PAD] \n",
      "target: 當 然 是 華 頭 華 腦 的 中 國 台 北 「 發 大 財 」 啦 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 4 324/625 loss : tensor(6.9477, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 藍 染 王 一 直 發 異 音 文 是 想 轉 向 嗎 ？ [PAD] [PAD] \n",
      "target: 他 發 異 音 文 好 久 了 你 現 在 才 問 ？ [PAD] [PAD] [PAD] \n",
      "e : 4 325/625 loss : tensor(6.8541, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 326/625 loss : tensor(7.0367, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 327/625 loss : tensor(7.0581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 328/625 loss : tensor(6.8843, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 329/625 loss : tensor(6.9914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 330/625 loss : tensor(6.9164, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 4 331/625 loss : tensor(6.8156, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 332/625 loss : tensor(7.3461, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 333/625 loss : tensor(6.9499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 334/625 loss : tensor(6.6775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 335/625 loss : tensor(7.3900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 336/625 loss : tensor(7.0873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 337/625 loss : tensor(7.0009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 338/625 loss : tensor(6.6240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 339/625 loss : tensor(6.8151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 340/625 loss : tensor(6.8451, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 341/625 loss : tensor(6.7660, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 342/625 loss : tensor(6.9286, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 343/625 loss : tensor(7.0601, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 344/625 loss : tensor(6.8373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 345/625 loss : tensor(6.9411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 346/625 loss : tensor(7.1763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 347/625 loss : tensor(7.6053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 348/625 loss : tensor(6.6567, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 349/625 loss : tensor(7.0505, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 350/625 loss : tensor(7.1808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 351/625 loss : tensor(6.9099, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 352/625 loss : tensor(7.0745, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 353/625 loss : tensor(7.2684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 354/625 loss : tensor(7.0560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 355/625 loss : tensor(7.2783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 356/625 loss : tensor(6.8360, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 當 企 鵝 妹 男 友 有 多 爽 的 八 卦 ? [PAD] [PAD] [PAD] [PAD] \n",
      "target: 就 用 外 來 種 騙 你 台 灣 人 啊 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 4 357/625 loss : tensor(7.2088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 358/625 loss : tensor(6.8145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 359/625 loss : tensor(6.8159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 360/625 loss : tensor(6.5484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 361/625 loss : tensor(6.6884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 362/625 loss : tensor(7.0830, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 363/625 loss : tensor(7.3764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 364/625 loss : tensor(6.8431, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 365/625 loss : tensor(6.7993, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 366/625 loss : tensor(6.7061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 367/625 loss : tensor(7.3261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 368/625 loss : tensor(7.0407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 369/625 loss : tensor(7.2287, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 370/625 loss : tensor(6.4690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 371/625 loss : tensor(6.9905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 372/625 loss : tensor(7.3690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 373/625 loss : tensor(7.0033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 374/625 loss : tensor(7.2114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 375/625 loss : tensor(7.1763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 376/625 loss : tensor(7.4388, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 377/625 loss : tensor(7.2636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 378/625 loss : tensor(7.4642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 379/625 loss : tensor(6.9358, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 380/625 loss : tensor(7.5846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 381/625 loss : tensor(6.7201, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 382/625 loss : tensor(7.4666, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 383/625 loss : tensor(6.5688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 384/625 loss : tensor(6.7344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 385/625 loss : tensor(7.1686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 386/625 loss : tensor(6.9864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 387/625 loss : tensor(6.6452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 388/625 loss : tensor(6.7348, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 389/625 loss : tensor(7.2108, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 390/625 loss : tensor(6.7190, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 391/625 loss : tensor(7.0491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 392/625 loss : tensor(6.9004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 393/625 loss : tensor(6.9247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 394/625 loss : tensor(6.5683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 395/625 loss : tensor(6.8027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 396/625 loss : tensor(7.1315, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 397/625 loss : tensor(6.5673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 398/625 loss : tensor(6.8918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 399/625 loss : tensor(6.8409, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 400/625 loss : tensor(7.2315, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 401/625 loss : tensor(6.5375, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 402/625 loss : tensor(6.8204, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 403/625 loss : tensor(7.0408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 404/625 loss : tensor(7.0903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 405/625 loss : tensor(7.0290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 406/625 loss : tensor(6.8700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 407/625 loss : tensor(6.6887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 408/625 loss : tensor(7.1023, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 409/625 loss : tensor(6.4972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 410/625 loss : tensor(6.7046, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 411/625 loss : tensor(7.2508, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 412/625 loss : tensor(6.8615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 413/625 loss : tensor(6.9911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 414/625 loss : tensor(7.2630, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 415/625 loss : tensor(7.4647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 416/625 loss : tensor(6.8929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 417/625 loss : tensor(6.5826, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 418/625 loss : tensor(7.0732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 419/625 loss : tensor(6.7610, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 420/625 loss : tensor(6.7536, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 421/625 loss : tensor(7.3077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 422/625 loss : tensor(7.1636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 423/625 loss : tensor(6.7547, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 424/625 loss : tensor(6.9760, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 425/625 loss : tensor(7.1126, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 426/625 loss : tensor(6.6429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 8 + 9 被 叫 8 + 9 會 生 氣 嗎 ？ [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "target: 8 + 9 是 台 語 憑 啥 17 是 國 語 ? 請 正 名 \" 渣 氣 \" \n",
      "e : 4 427/625 loss : tensor(6.4785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 428/625 loss : tensor(7.0855, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 429/625 loss : tensor(6.9648, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 4 430/625 loss : tensor(6.2408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 431/625 loss : tensor(6.6656, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 432/625 loss : tensor(6.9829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 433/625 loss : tensor(6.4516, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 434/625 loss : tensor(6.6115, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 435/625 loss : tensor(7.1332, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 436/625 loss : tensor(6.7829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 437/625 loss : tensor(6.7868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 438/625 loss : tensor(6.3748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 439/625 loss : tensor(7.3323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 440/625 loss : tensor(6.6279, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 441/625 loss : tensor(6.6482, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 442/625 loss : tensor(6.9714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 443/625 loss : tensor(6.8515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 444/625 loss : tensor(7.3559, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 445/625 loss : tensor(7.1850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 446/625 loss : tensor(7.2380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 447/625 loss : tensor(6.8983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 448/625 loss : tensor(6.9313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 449/625 loss : tensor(7.0074, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 450/625 loss : tensor(6.6707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 451/625 loss : tensor(7.2536, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 452/625 loss : tensor(6.9456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 453/625 loss : tensor(7.2155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 454/625 loss : tensor(7.0715, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 455/625 loss : tensor(6.6996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 456/625 loss : tensor(6.8318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 457/625 loss : tensor(7.0046, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 458/625 loss : tensor(6.7456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 459/625 loss : tensor(6.9657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 460/625 loss : tensor(6.6596, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 461/625 loss : tensor(7.4337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 所 以 羅 東 夜 市 到 底 在 紅 啥 . . . ? [PAD] [PAD] [PAD] \n",
      "target: 就 跟 中 國 人 愛 來 台 灣 拉 屎 一 樣 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 4 462/625 loss : tensor(6.7820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 463/625 loss : tensor(7.1458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 464/625 loss : tensor(7.0550, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 465/625 loss : tensor(6.8356, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 466/625 loss : tensor(7.2964, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 467/625 loss : tensor(6.8995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 468/625 loss : tensor(7.3521, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 469/625 loss : tensor(6.7980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 470/625 loss : tensor(6.7918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 471/625 loss : tensor(7.0787, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 472/625 loss : tensor(6.9071, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 473/625 loss : tensor(6.6866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 474/625 loss : tensor(7.0043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 475/625 loss : tensor(6.7725, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 476/625 loss : tensor(6.8965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 477/625 loss : tensor(6.9311, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 478/625 loss : tensor(6.8895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 479/625 loss : tensor(7.1263, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 480/625 loss : tensor(6.8175, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 481/625 loss : tensor(6.6396, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 482/625 loss : tensor(6.7525, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 483/625 loss : tensor(6.8631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 484/625 loss : tensor(7.1017, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 485/625 loss : tensor(6.4409, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 486/625 loss : tensor(7.3381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 487/625 loss : tensor(6.8184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 488/625 loss : tensor(6.8267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 489/625 loss : tensor(7.1107, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 490/625 loss : tensor(6.9374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 491/625 loss : tensor(6.7858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 4 L : tensor(6.9304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "e : 5 1/625 loss : tensor(6.9082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 2/625 loss : tensor(6.7770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 3/625 loss : tensor(6.7952, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 4/625 loss : tensor(7.4318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 5/625 loss : tensor(6.9850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 6/625 loss : tensor(7.0261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 7/625 loss : tensor(6.9233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 8/625 loss : tensor(6.8629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 為 什 麼 大 家 不 去 打 砲 還 看 廢 文 ? [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "target: 幹 你 老 師 這 圖 真 他 媽 的 噁 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 5 9/625 loss : tensor(7.0347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 10/625 loss : tensor(6.7547, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 11/625 loss : tensor(6.9905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 12/625 loss : tensor(6.9686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 13/625 loss : tensor(7.1227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 14/625 loss : tensor(7.5897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 15/625 loss : tensor(7.2436, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 16/625 loss : tensor(7.1220, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 17/625 loss : tensor(6.9911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 18/625 loss : tensor(7.0102, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 19/625 loss : tensor(6.9368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 20/625 loss : tensor(6.7136, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 21/625 loss : tensor(7.3547, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 22/625 loss : tensor(6.8222, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 23/625 loss : tensor(6.9177, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 24/625 loss : tensor(6.7690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 25/625 loss : tensor(7.3021, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 26/625 loss : tensor(6.6905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 27/625 loss : tensor(6.8117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 28/625 loss : tensor(6.8522, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 29/625 loss : tensor(7.0452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 30/625 loss : tensor(6.8891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 31/625 loss : tensor(7.1198, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 32/625 loss : tensor(6.9016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 33/625 loss : tensor(6.8797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 34/625 loss : tensor(6.9354, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 35/625 loss : tensor(6.9648, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 36/625 loss : tensor(6.6673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 37/625 loss : tensor(6.7096, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 5 38/625 loss : tensor(7.1508, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 39/625 loss : tensor(7.0545, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 40/625 loss : tensor(6.6904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 41/625 loss : tensor(7.1424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 42/625 loss : tensor(6.6092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 43/625 loss : tensor(6.8716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 44/625 loss : tensor(6.9475, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 45/625 loss : tensor(6.8815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 46/625 loss : tensor(7.1763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 47/625 loss : tensor(6.4397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 48/625 loss : tensor(6.9375, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 49/625 loss : tensor(6.7986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 50/625 loss : tensor(6.6371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 51/625 loss : tensor(6.8483, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 52/625 loss : tensor(6.9094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 53/625 loss : tensor(6.9536, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 54/625 loss : tensor(6.7618, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 55/625 loss : tensor(6.7884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 56/625 loss : tensor(7.0788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 57/625 loss : tensor(6.8711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 58/625 loss : tensor(6.6480, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 59/625 loss : tensor(6.5185, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 60/625 loss : tensor(6.7823, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 61/625 loss : tensor(6.9198, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 62/625 loss : tensor(7.0551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 63/625 loss : tensor(7.1199, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 64/625 loss : tensor(7.2801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 65/625 loss : tensor(6.8826, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 66/625 loss : tensor(6.8467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 67/625 loss : tensor(7.2133, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 68/625 loss : tensor(6.5799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 69/625 loss : tensor(6.8448, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 70/625 loss : tensor(6.7812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 71/625 loss : tensor(7.2081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 72/625 loss : tensor(7.3340, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 73/625 loss : tensor(7.1241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 74/625 loss : tensor(6.9980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 75/625 loss : tensor(6.7391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 76/625 loss : tensor(6.8443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 77/625 loss : tensor(6.5552, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 78/625 loss : tensor(6.6719, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 79/625 loss : tensor(6.7167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 80/625 loss : tensor(7.1221, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 81/625 loss : tensor(6.8508, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 82/625 loss : tensor(6.7812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 83/625 loss : tensor(7.0125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 終 極 系 列 是 不 是 台 灣 有 平 行 時 空 的 第 一 齣 劇 \n",
      "target: 以 前 超 好 看 現 在 越 來 越 爛 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 5 84/625 loss : tensor(6.9686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 85/625 loss : tensor(7.3086, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 86/625 loss : tensor(6.4686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 87/625 loss : tensor(6.9653, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 88/625 loss : tensor(6.3249, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 89/625 loss : tensor(6.7288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 90/625 loss : tensor(6.7381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 91/625 loss : tensor(6.8645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 92/625 loss : tensor(7.0458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 93/625 loss : tensor(6.7930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 94/625 loss : tensor(6.9840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 95/625 loss : tensor(6.6951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 96/625 loss : tensor(6.9077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 97/625 loss : tensor(6.5978, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 98/625 loss : tensor(6.7347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 99/625 loss : tensor(6.4620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 100/625 loss : tensor(6.8277, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 101/625 loss : tensor(7.6063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 102/625 loss : tensor(6.8919, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 103/625 loss : tensor(6.8843, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 104/625 loss : tensor(6.9350, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 105/625 loss : tensor(6.7633, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 106/625 loss : tensor(7.2372, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 107/625 loss : tensor(6.7174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 108/625 loss : tensor(6.7874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 109/625 loss : tensor(7.2466, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 110/625 loss : tensor(6.6111, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 111/625 loss : tensor(6.8126, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 112/625 loss : tensor(7.1035, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 113/625 loss : tensor(6.6366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 114/625 loss : tensor(6.8247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 115/625 loss : tensor(6.8222, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 116/625 loss : tensor(7.3218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 117/625 loss : tensor(6.6524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 118/625 loss : tensor(7.1045, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 119/625 loss : tensor(6.7717, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 120/625 loss : tensor(6.6583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 121/625 loss : tensor(7.2681, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 122/625 loss : tensor(6.9388, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 123/625 loss : tensor(6.8885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 124/625 loss : tensor(6.9455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 125/625 loss : tensor(6.9769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 126/625 loss : tensor(6.7969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 127/625 loss : tensor(6.9719, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 128/625 loss : tensor(6.9339, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 129/625 loss : tensor(6.9604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 130/625 loss : tensor(6.6517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 131/625 loss : tensor(6.4301, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 132/625 loss : tensor(7.0734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 133/625 loss : tensor(7.1867, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 134/625 loss : tensor(7.6320, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 135/625 loss : tensor(6.7318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 136/625 loss : tensor(7.1768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 137/625 loss : tensor(6.8838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 毆 打 同 學 不 用 記 過 遲 到 卻 被 記 警 告 ? ? [PAD] \n",
      "target: 誰 在 乎 我 高 中 沒 準 時 到 過 學 校 也 是 可 以 畢 業 [PAD] [PAD] [PAD] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 5 138/625 loss : tensor(6.6478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 139/625 loss : tensor(6.6217, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 140/625 loss : tensor(6.8796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 141/625 loss : tensor(7.2172, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 142/625 loss : tensor(7.0280, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 143/625 loss : tensor(6.8155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 144/625 loss : tensor(6.6707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 145/625 loss : tensor(6.8230, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 146/625 loss : tensor(6.6454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 147/625 loss : tensor(6.6818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 148/625 loss : tensor(7.0070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 149/625 loss : tensor(6.8752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 150/625 loss : tensor(6.7464, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 151/625 loss : tensor(6.7581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 152/625 loss : tensor(7.2140, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 153/625 loss : tensor(7.1022, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 154/625 loss : tensor(7.5278, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 155/625 loss : tensor(7.3927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 156/625 loss : tensor(6.8287, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 157/625 loss : tensor(7.3298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 158/625 loss : tensor(7.1452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 159/625 loss : tensor(6.5826, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 160/625 loss : tensor(7.5415, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 161/625 loss : tensor(7.0097, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 162/625 loss : tensor(6.7983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 163/625 loss : tensor(6.7745, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 164/625 loss : tensor(6.8943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 165/625 loss : tensor(6.9978, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 166/625 loss : tensor(6.9909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 167/625 loss : tensor(6.5849, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 168/625 loss : tensor(7.1350, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 169/625 loss : tensor(6.5626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 170/625 loss : tensor(7.0153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 171/625 loss : tensor(6.8801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 172/625 loss : tensor(6.9210, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 173/625 loss : tensor(7.3899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 174/625 loss : tensor(7.5444, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 175/625 loss : tensor(7.0925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 176/625 loss : tensor(6.7740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 177/625 loss : tensor(6.9412, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 178/625 loss : tensor(6.9329, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 179/625 loss : tensor(7.0854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 180/625 loss : tensor(6.9911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 181/625 loss : tensor(6.6501, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 182/625 loss : tensor(7.0940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 183/625 loss : tensor(7.2303, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 184/625 loss : tensor(6.8870, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 185/625 loss : tensor(7.3465, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 186/625 loss : tensor(6.6874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 187/625 loss : tensor(6.7307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 188/625 loss : tensor(7.1138, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 189/625 loss : tensor(6.7491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 190/625 loss : tensor(6.9654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 191/625 loss : tensor(6.6082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 192/625 loss : tensor(6.8935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 193/625 loss : tensor(7.0451, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 194/625 loss : tensor(6.5621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 195/625 loss : tensor(6.4970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 196/625 loss : tensor(7.0395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 197/625 loss : tensor(6.9277, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 198/625 loss : tensor(7.3462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 199/625 loss : tensor(6.8798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 200/625 loss : tensor(6.6605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 201/625 loss : tensor(6.6979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 202/625 loss : tensor(7.1794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "error.....\n",
      "target: 有 沒 有 出 桶 的 掛 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "target: 卦 啦 幹 字 都 不 會 打 可 憐 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "e : 5 203/625 loss : tensor(7.4680, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 204/625 loss : tensor(7.0103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 205/625 loss : tensor(6.9925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 206/625 loss : tensor(7.2842, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 207/625 loss : tensor(6.9697, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 208/625 loss : tensor(6.9080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 209/625 loss : tensor(6.6470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 210/625 loss : tensor(6.9478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 211/625 loss : tensor(6.9678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 212/625 loss : tensor(6.8198, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 213/625 loss : tensor(6.7947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 214/625 loss : tensor(7.0377, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 215/625 loss : tensor(6.7410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 216/625 loss : tensor(6.9830, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 217/625 loss : tensor(6.9902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 218/625 loss : tensor(6.6692, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 219/625 loss : tensor(7.1147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 220/625 loss : tensor(6.7244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 221/625 loss : tensor(6.5004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 222/625 loss : tensor(7.2123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 223/625 loss : tensor(6.9138, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 224/625 loss : tensor(7.1887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 225/625 loss : tensor(7.3395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 226/625 loss : tensor(6.5586, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 227/625 loss : tensor(7.1541, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 228/625 loss : tensor(6.7924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 229/625 loss : tensor(7.3433, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 230/625 loss : tensor(6.8952, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 231/625 loss : tensor(7.4303, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 232/625 loss : tensor(6.8571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 233/625 loss : tensor(7.0505, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 234/625 loss : tensor(7.1382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 235/625 loss : tensor(6.9272, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 236/625 loss : tensor(7.0215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 237/625 loss : tensor(6.8372, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 238/625 loss : tensor(6.9414, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e : 5 239/625 loss : tensor(6.8934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 240/625 loss : tensor(6.7519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 241/625 loss : tensor(6.4923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 242/625 loss : tensor(6.8189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 243/625 loss : tensor(6.9918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 244/625 loss : tensor(7.0374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 245/625 loss : tensor(6.7327, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 246/625 loss : tensor(6.6089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 247/625 loss : tensor(6.9075, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 248/625 loss : tensor(6.9567, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 249/625 loss : tensor(6.6951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 250/625 loss : tensor(7.4271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 251/625 loss : tensor(7.0482, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 252/625 loss : tensor(7.0273, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 253/625 loss : tensor(6.9720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 254/625 loss : tensor(7.2093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 255/625 loss : tensor(6.9365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 256/625 loss : tensor(6.8416, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 257/625 loss : tensor(6.6816, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 258/625 loss : tensor(7.1153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 259/625 loss : tensor(7.2034, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 260/625 loss : tensor(6.8716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 261/625 loss : tensor(6.9838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 262/625 loss : tensor(6.9032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 263/625 loss : tensor(6.5737, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 264/625 loss : tensor(6.6608, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 265/625 loss : tensor(6.8249, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 266/625 loss : tensor(6.7765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 267/625 loss : tensor(7.2596, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 268/625 loss : tensor(7.1802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 269/625 loss : tensor(7.1105, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 270/625 loss : tensor(7.2065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "e : 5 271/625 loss : tensor(7.0061, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIALOG = True\n",
    "for e in range(6): #lucky number\n",
    "    \n",
    "    mean_loss = 0\n",
    "    count = 0\n",
    "    \n",
    "    for input, target ,mask_Q ,mask_A in train_data:\n",
    "        \n",
    "        try:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            target = target.view(target.shape[0],target.shape[1])\n",
    "            input = input.view(input.shape[0],input.shape[1])\n",
    "            mask_Q = mask_Q.view(mask_Q.shape[0],mask_Q.shape[1])\n",
    "            mask_A = mask_A.view(mask_A.shape[0],mask_A.shape[1])\n",
    "\n",
    "            output =  g_model(input, target, mask_Q, mask_A,0.01)\n",
    "            output_dim = output.shape[-1]\n",
    "            loss = loss_fn(output[:-1].view(-1, output_dim), target[:-1].view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            count += 1\n",
    "            mean_loss+=loss\n",
    "     \n",
    "        except RuntimeError: \n",
    "            print('error.....')\n",
    "            print_index_tensor(input)\n",
    "            print_index_tensor(target)\n",
    "        else:\n",
    "            print(\"e : \" + str(e) + ' ' + str(count) + '/' + str(iter) + ' loss : ' + str(loss))\n",
    "\n",
    "    print(\"e : \"+str(e)+\" L : \"+str(mean_loss/count))\n",
    "        \n",
    "    torch.save(g_model, \"./model_\"+str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Seq2Seq. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type TransBertEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type PositionalEncoding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type TransBertDecoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type GruEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type GruDecoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type DialogDNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# torch.save(g_model, \"./model_test2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = DataLoader(v_set, shuffle=True, batch_size=10, collate_fn=create_mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: [UNK] 有 洩 漏 過 誰 的 個 資 嗎 ? [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "target: 小 時 候 不 念 書 長 大 當 記 者 沒 法 度 [PAD] [PAD] [PAD] [PAD] \n",
      "chatbot: 的 的 的 的 不 的 不 的 不 一 的 的 不 的 不 不 的 的 \n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIALOG = False\n",
    "for input, target ,mask_Q ,mask_A in test_data:\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    target = target.view(target.shape[0],target.shape[1])\n",
    "    input = input.view(input.shape[0],input.shape[1])\n",
    "    mask_Q = mask_Q.view(mask_Q.shape[0],mask_Q.shape[1])\n",
    "    mask_A = mask_A.view(mask_A.shape[0],mask_A.shape[1])\n",
    "\n",
    "    output =  g_model(input, target, mask_Q, mask_A,0.01)\n",
    "    \n",
    "    print_index_tensor(input)\n",
    "    print_index_tensor(target)\n",
    "    print_chat(output)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
